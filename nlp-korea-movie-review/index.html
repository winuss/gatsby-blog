<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.b8221ec0ff064b96422d.css">code[class*=language-],pre[class*=language-]{color:#f8f8f2;background:none;text-shadow:0 1px rgba(0,0,0,.3);font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto;border-radius:.3em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#272822}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#708090}.token.punctuation{color:#f8f8f2}.token.namespace{opacity:.7}.token.constant,.token.deleted,.token.property,.token.symbol,.token.tag{color:#f92672}.token.boolean,.token.number{color:#ae81ff}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#a6e22e}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url,.token.variable{color:#f8f8f2}.token.atrule,.token.attr-value,.token.class-name,.token.function{color:#e6db74}.token.keyword{color:#66d9ef}.token.important,.token.regex{color:#fd971f}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}</style><meta name="generator" content="Gatsby 2.21.0"/><title data-react-helmet="true">NLP - 한국어 영화 리뷰 감정분석 - DevTimes</title><meta data-react-helmet="true" name="description" content="네이버 영화 리뷰 데이터를 이용한 긍정/부정 예측하기"/><meta data-react-helmet="true" name="og:title" content="NLP - 한국어 영화 리뷰 감정분석 - DevTimes"/><meta data-react-helmet="true" name="og:type" content="website"/><meta data-react-helmet="true" name="og:description" content="네이버 영화 리뷰 데이터를 이용한 긍정/부정 예측하기"/><meta data-react-helmet="true" name="og:url" content="https://devtimes.com/nlp-korea-movie-review"/><meta data-react-helmet="true" name="twitter:label1" content="Written by"/><meta data-react-helmet="true" name="twitter:data1" content="winuss"/><meta data-react-helmet="true" name="twitter:card" content="summary"/><meta data-react-helmet="true" name="twitter:creator" content="winuss"/><meta data-react-helmet="true" name="twitter:title" content="NLP - 한국어 영화 리뷰 감정분석 - DevTimes"/><meta data-react-helmet="true" name="twitter:description" content="네이버 영화 리뷰 데이터를 이용한 긍정/부정 예측하기"/><meta data-react-helmet="true" name="keywords" content="angular, python, machine learning, deep learning, game, ML-DL, ML, NLP"/><meta data-react-helmet="true" name="article:published_time" content="2020-05-24T00:00:00.000Z"/><meta data-react-helmet="true" name="article:modified_time" content="2020-05-24T00:00:00.000Z"/><meta data-react-helmet="true" name="twitter:label2" content="Filed under"/><meta data-react-helmet="true" name="twitter:data2" content="ML-DL"/><meta data-react-helmet="true" name="og:image" content="https://devtimes.com//static/3081b292a1f8afbb61de9dd1ab205863/c0491/cover.png"/><meta data-react-helmet="true" name="twitter:image" content="https://devtimes.com//static/3081b292a1f8afbb61de9dd1ab205863/c0491/cover.png"/><script data-react-helmet="true" type="application/ld+json">
        {
          "@context": "https://schema.org/",
          "@type": "Article",
          "author": {
            "@type": "Person",
            "name": "winuss"
          },
          "keywords": "ML-DL, ML, NLP",
          "headline": "NLP - 한국어 영화 리뷰 감정분석 - DevTimes",
          "url": "https://devtimes.com/nlp-korea-movie-review",
          "datePublished": "2020-05-24T00:00:00.000Z",
          "dateModified": "2020-05-24T00:00:00.000Z",
          "image": {
            "@type": "ImageObject",
            "url": "https://devtimes.com//static/3081b292a1f8afbb61de9dd1ab205863/c0491/cover.png",
            "width": "1000",
            "height": "520"
          },
          "publisher": {
            "@type": "Organization",
            "name": "DevTimes"
          },
          "description": "네이버 영화 리뷰 데이터를 이용한 긍정/부정 예측하기",
          "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://devtimes.com"
          }
        }
      </script><style data-styled="gOVsKi fbNACK dqKNZj JgKdn jnMIuM hqRQjv gWKWdg jMoVC fiqFtq llrxFq imSJbr JexoF iRWYuq bOhMpF eMHMJv fymZCI bdTsjL eHCGZv ixYMGE gDLYpk hKDtNq guoPGM hyzxOc kAaKev ewrmMm dWgKtp kWRivk rrUdK gmpFBk cCbMYU kStElJ frcJlw cNysWr htFYTF hdhrBK kcCrhV cKJeHJ evGsdC dkniVZ eysmNL" data-styled-version="4.4.1">
/* sc-component-id: sc-global-2451124928 */
html{box-sizing:border-box;background-color:#fafafa;} body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;line-height:1.9em;} *{box-sizing:border-box;} h1,h2,h3,h4,h5,h6{outline:none;} a{color:#000;-webkit-text-decoration:none;text-decoration:none;} .gatsby-highlight{font-size:0.85em;background-color:#282a36;border-radius:0.2em;padding:1em 1.4em;overflow:auto;width:100%;border:0.1em solid #c6c6c8;margin-bottom:6px;} div[data-language='text'].gatsby-highlight{background-color:#f0f0f0;border:0.03em solid #c6c6c8;margin-left:2px;margin-right:2px;width:calc(100% - 4px);} .gatsby-highlight pre.language-text code.language-text{color:#000;text-shadow:none;} .gatsby-highlight pre[class*='language-']{background-color:transparent;margin:0;padding:0;overflow:initial;float:left;min-width:100%;} .gatsby-highlight-code-line{background-color:#353631;display:block;margin-right:-1em;margin-left:-1em;padding-right:1em;padding-left:0.75em;} .remark-sticky-table{border-radius:2px;margin:32px 0px;} .remark-sticky-table-table{border-collapse:collapse;box-sizing:border-box;border:1px solid #bcbcbc;width:auto;} .remark-sticky-table-th{background-color:#f7f7f7;font-weight:600;text-align:left;border-bottom:1px solid #b8bcc9;} .remark-sticky-table-tbody:nth-child(odd){background-color:#fafafa;} .remark-sticky-table-th,.remark-sticky-table-td{padding:4px 12px;} table.dataframe{border-collapse:collapse;font-size:0.75em;margin-bottom:8px;margin-left:2px;margin-right:2px;line-height:2em;display:block;overflow-x:auto;white-space:nowrap;border:1px solid transparent;} table.dataframe > tbody{text-align:right;} .dataframe td,.dataframe th{border:1px solid #bcbcbc;padding:0px 12px;} .dataframe tr:nth-child(even){background-color:#f2f2f2;} .dataframe tr:hover{background-color:#d6d9e0;} .dataframe th{background-color:#f7f7f7;padding:0px 12px;}
/* sc-component-id: style__NavContainer-sc-1nu4t1g-0 */
.gOVsKi{z-index:1000;background-color:#20232a;position:-webkit-sticky;position:sticky;top:0;box-shadow:0 0 3px rgba(0,0,0,.03),0 3px 46px rgba(0,0,0,.07);}
/* sc-component-id: style__Nav-sc-1nu4t1g-1 */
.fbNACK{width:1260px;margin-left:auto;margin-right:auto;max-width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;position:relative;} @media (max-width:1300px){.fbNACK{padding:0 20px;}}
/* sc-component-id: style__NavWrapper-sc-1nu4t1g-2 */
.jnMIuM{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;width:100%;height:70px;white-space:nowrap;} @media (max-width:576px){.jnMIuM{width:90%;}}
/* sc-component-id: style__NavMenu-sc-1nu4t1g-3 */
.hqRQjv{-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;list-style-type:none;margin:0;padding:0;} @media (max-width:576px){.hqRQjv{width:80%;overflow-x:auto;overflow-y:hidden;-webkit-mask-image:linear-gradient(to right,transparent,#000 25px,#000 90%,transparent);mask-image:linear-gradient(to right,transparent,#000 25px,#000 90%,transparent);}}.gWKWdg{-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;list-style-type:none;margin:0;padding:0;}
/* sc-component-id: style__NavMenuItem-sc-1nu4t1g-4 */
.jMoVC{cursor:pointer;display:inline-block;border:0;background:transparent;outline:none;-webkit-text-decoration:none;text-decoration:none;}
/* sc-component-id: style__NavLink-sc-1nu4t1g-5 */
.fiqFtq{color:#fff;opacity:.8;padding:16px;-webkit-transition:opacity .5s;transition:opacity .5s;} .fiqFtq:hover{opacity:1;}
/* sc-component-id: style__SearchContainer-sc-1nu4t1g-6 */
.llrxFq{-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;position:relative;}
/* sc-component-id: style__ToggleSearchButton-sc-1nu4t1g-7 */
.imSJbr{cursor:pointer;color:#fff;opacity:.8;background:none;outline:none;border:0;-webkit-transition:opacity .5s;transition:opacity .5s;} .imSJbr:hover{opacity:1;}
/* sc-component-id: logo__LogoImage-nd9ri7-0 */
.JgKdn{max-height:30px;width:30px;margin-right:45px;} @media (max-width:576px){.JgKdn{margin-right:15px;}}
/* sc-component-id: logo__HomeLink-nd9ri7-1 */
.dqKNZj{-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;height:30px;}
/* sc-component-id: style__StyledFooter-sc-1xdlo4d-0 */
.hdhrBK{max-width:100%;padding:10px 0;z-index:700;position:relative;font-size:.9em;margin-top:50px;}
/* sc-component-id: style__FooterContainer-sc-1xdlo4d-1 */
.kcCrhV{width:1260px;margin-left:auto;margin-right:auto;max-width:100%;text-align:right;line-height:1.1em;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;} @media (max-width:1300px){.kcCrhV{padding:0 20px;}}
/* sc-component-id: style__Copyright-sc-1xdlo4d-2 */
.dkniVZ{margin:0;}
/* sc-component-id: style__DesignBy-sc-1xdlo4d-3 */
.eysmNL{margin:0;opacity:.8;font-size:.8em;} .eysmNL a{font-weight:bold;-webkit-text-decoration:none;text-decoration:none;color:#000;} .eysmNL a:hover{-webkit-text-decoration:underline;text-decoration:underline;}
/* sc-component-id: style__StyledNav-sc-1xdlo4d-4 */
.cKJeHJ ul{list-style-type:none;margin:0;padding:0;} .cKJeHJ li{display:inline-block;margin-right:25px;} .cKJeHJ li:last-child{margin-right:0;}
/* sc-component-id: style__FooterMenuItem-sc-1xdlo4d-5 */
.evGsdC{color:#000;-webkit-text-decoration:none;text-decoration:none;}
/* sc-component-id: toc__StyledNav-dzz3d3-0 */
.kAaKev .toc-list{list-style-type:none;margin:0;padding:0 0 0 0;border-left:2.5px solid #dcdee4;} .kAaKev .toc-list .toc-list{padding-top:10px;} .kAaKev .toc-list-item{line-height:1.2em;padding-bottom:10px;} .kAaKev .toc-list-item:last-child{padding-bottom:0;} .kAaKev .toc-link{color:#808080;-webkit-text-decoration:none;text-decoration:none;font-size:0.9em;font-weight:550;padding-left:8px;} .kAaKev .is-active-link{margin-left:-2.5px;padding-left:8px;border-left:2.5px solid #13acee;color:#099bcc;}
/* sc-component-id: reading-progress__ReadingProgressBar-i1hf8v-0 */
.JexoF{position:-webkit-sticky;position:sticky;height:5px;top:70px;background-color:#4bc822;z-index:500;}
/* sc-component-id: social-channel-list__StyledSocialChannels-z1p8fq-0 */
.cNysWr{list-style-type:none;margin:0;padding:0;}
/* sc-component-id: social-channel-list__StyledSocialChannel-z1p8fq-1 */
.htFYTF{display:inline-block;margin:0 10px;font-size:1.6em;opacity:.7;-webkit-transition:opacity .5s;transition:opacity .5s;} .htFYTF:hover{opacity:1;}
/* sc-component-id: avatar__StyledAvatar-sc-1papyes-0 */
.cCbMYU{max-width:70px;border-radius:100%;}
/* sc-component-id: bio__StyledBio-j3ch0c-0 */
.gmpFBk{margin:auto;text-align:center;width:100%;}
/* sc-component-id: bio__AuthorDescription-j3ch0c-1 */
.frcJlw{margin:10px 0 13px;} .frcJlw a{color:#000;-webkit-text-decoration:underline;text-decoration:underline;}
/* sc-component-id: bio__AuthorName-j3ch0c-2 */
.kStElJ{margin:10px;}
/* sc-component-id: post__PostContainer-z0x2sj-0 */
.iRWYuq{width:1260px;margin-left:auto;margin-right:auto;max-width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding:0 !important;} @media (max-width:1300px){.iRWYuq{padding:0 20px;}}
/* sc-component-id: post__LeftSidebar-z0x2sj-1 */
.guoPGM{min-width:300px;max-width:300px;-webkit-transition:opacity .5s,z-index .5s;transition:opacity .5s,z-index .5s;font-size:0.9em;margin-left:20px;} @media (max-width:1300px){.guoPGM{position:fixed;opacity:0;z-index:-1;background-color:#fff;width:100% !important;padding:0 20px;margin-top:-5px;height:calc(100vh - 70px);}}
/* sc-component-id: post__PostContent-z0x2sj-2 */
.bOhMpF{margin-top:-5px;border-right:1px #e5eff5 solid;border-left:1px #e5eff5 solid;background-color:#fff;box-shadow:0 0 3px rgba(0,0,0,.03),0 3px 46px rgba(0,0,0,.1);z-index:10;width:1035px;max-width:100%;} .bOhMpF li > a,.bOhMpF p > a{color:#a4cbb8;border-bottom:2px #a4cbb8 solid;} .bOhMpF pre{margin:30px 0;} .bOhMpF blockquote{border-left:4px #a4cbb8 solid;background-color:#fafafa;margin:30px 0;padding:5px 20px;border-radius:.3em;} .bOhMpF h3::before,.bOhMpF h4::before,.bOhMpF h5::before,.bOhMpF h6::before{display:block;content:" ";height:90px;margin-top:-90px;visibility:hidden;} .bOhMpF h2{border-top:1px solid #ececec;margin-top:44px;padding-top:40px;line-height:1.2;} .bOhMpF code[class*="language-text"]{padding:2px;font-size:0.9em;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;} .bOhMpF p > .language-text{background-color:#f2e6e9;padding:0 4px 2px 4px;font-weight:600;color:#c7254e;text-align:center;} .bOhMpF p > img{max-width:100%;border-radius:.3em;margin:30px 0;} .bOhMpF hr{border-top:1px solid #ececec;border-bottom:0;margin-top:44px;margin-bottom:40px;} .bOhMpF .gatsby-resp-image-link{margin:30px 0;max-width:100%;} .bOhMpF .gatsby-resp-image-link .gatsby-resp-image-image{border-radius:.3em;}
/* sc-component-id: post__TocWrapper-z0x2sj-3 */
.hyzxOc{position:-webkit-sticky;position:sticky;top:70px;padding:40px 30px 40px 0;}
/* sc-component-id: post__PostHeader-z0x2sj-4 */
.eMHMJv{padding:40px;} @media (max-width:576px){.eMHMJv{padding:20px;}}
/* sc-component-id: post__FeaturedImage-z0x2sj-5 */
.eHCGZv{border-radius:0;} @media (max-width:1300px){.eHCGZv{margin-left:-1px;margin-right:-1px;}}
/* sc-component-id: post__StyledPost-z0x2sj-6 */
.ixYMGE{padding:40px;} @media (max-width:576px){.ixYMGE{padding:20px;}}
/* sc-component-id: post__PostMeta-z0x2sj-7 */
.fymZCI{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;opacity:.8;font-size:.9em;}
/* sc-component-id: post__PostTitle-z0x2sj-8 */
.bdTsjL{margin:0;padding:0;}
/* sc-component-id: post__PostFooter-z0x2sj-9 */
.gDLYpk{background-color:#fafafa;font-size:.8em;color:#666;padding:40px;line-height:1em;} .gDLYpk p{margin:5px 0;}
/* sc-component-id: post__FooterTagLink-z0x2sj-10 */
.hKDtNq{color:#000 !important;-webkit-text-decoration:none;text-decoration:none;border-bottom:0 !important;}
/* sc-component-id: post__PostAddition-z0x2sj-11 */
.dWgKtp{background-color:#fff;border-top:1px #e5eff5 solid;border-bottom:1px #e5eff5 solid;z-index:700;position:relative;padding:40px;}
/* sc-component-id: post__PostAdditionContent-z0x2sj-12 */
.kWRivk{width:1260px;margin-left:auto;margin-right:auto;max-width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;} @media (max-width:1300px){.kWRivk{padding:0 20px;}}
/* sc-component-id: post__BioWrapper-z0x2sj-13 */
.rrUdK{width:50%;margin:auto;} @media (max-width:576px){.rrUdK{width:100%;}}
/* sc-component-id: post__ToggleTocButton-z0x2sj-14 */
.ewrmMm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;position:fixed;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;right:20px;bottom:20px;border-radius:100%;box-shadow:0 0 3px rgba(0,0,0,.03),0 3px 46px rgba(0,0,0,.1);border:0;z-index:5000;width:50px;height:50px;background-color:#20232a;color:#fff;outline:none;} @media (min-width:1300px){.ewrmMm{display:none;}}</style><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link rel="icon" href="/favicon-32x32.png?v=53395c7476cdf4ad211173db66a6affd"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="theme-color" content="#a4cbb8"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=53395c7476cdf4ad211173db66a6affd"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=53395c7476cdf4ad211173db66a6affd"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=53395c7476cdf4ad211173db66a6affd"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=53395c7476cdf4ad211173db66a6affd"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=53395c7476cdf4ad211173db66a6affd"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=53395c7476cdf4ad211173db66a6affd"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=53395c7476cdf4ad211173db66a6affd"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=53395c7476cdf4ad211173db66a6affd"/><link rel="preconnect dns-prefetch" href="https://www.google-analytics.com"/><style type="text/css">
    .anchor.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .anchor.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .anchor svg,
    h2 .anchor svg,
    h3 .anchor svg,
    h4 .anchor svg,
    h5 .anchor svg,
    h6 .anchor svg {
      visibility: hidden;
    }
    h1:hover .anchor svg,
    h2:hover .anchor svg,
    h3:hover .anchor svg,
    h4:hover .anchor svg,
    h5:hover .anchor svg,
    h6:hover .anchor svg,
    h1 .anchor:focus svg,
    h2 .anchor:focus svg,
    h3 .anchor:focus svg,
    h4 .anchor:focus svg,
    h5 .anchor:focus svg,
    h6 .anchor:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="/rss.xml"/><link as="script" rel="preload" href="/webpack-runtime-54fc4c4fe4b49e1e33de.js"/><link as="script" rel="preload" href="/framework-737c3e16d462c41141c7.js"/><link as="script" rel="preload" href="/app-a8b2574222d925c54afd.js"/><link as="script" rel="preload" href="/styles-85581d4dae49207538a9.js"/><link as="script" rel="preload" href="/1bfc9850-693458f4bfc03c5b78c9.js"/><link as="script" rel="preload" href="/6c18e55fdd71cb6af87612710cbe2c0cb61bdd56-92ca3db2def247415ce0.js"/><link as="script" rel="preload" href="/component---src-templates-post-tsx-8a7ad919cf47b755089e.js"/><link as="fetch" rel="preload" href="/page-data/nlp-korea-movie-review/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="style__NavContainer-sc-1nu4t1g-0 gOVsKi"><div class="common__Container-sc-1wbwqlx-0 style__Nav-sc-1nu4t1g-1 fbNACK"><a class="logo__HomeLink-nd9ri7-1 dqKNZj" href="/"><div class="logo__LogoImage-nd9ri7-0 JgKdn gatsby-image-wrapper" style="position:relative;overflow:hidden;display:inline-block;width:30px;height:30px"><img aria-hidden="true" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAAC1UlEQVQ4y4WVTUubQRCAo6bQQEvxH+SSQw4SCOI5kGsiQtNCCTQeepD+BgVbDzlqsRSFBGKgBJpDTzlEbfUaFTVQSyAQ7QdYvIgt0eT9mOnMZme7BqELk9ndd/bZmdnZTQAAAtxYk4zq/j2SJyQVklMSBxFd0t9IPpA8o/F9bTtKfcUQrToyIIM09b+i1TzPU2I3smuTehoIGMbIXbDX1hr2yCXt83otvjUv4DcWVP1ImK+0jU99j0RBKpUKzM/Pw+LiIqytrYHrujDgKBtPQ9/e8pImUhaMBX3fVwsTiQS7ryQcDuPNzY0A1Y94S3pWYEEaf9GTsiMQUO2QSqUMcGJiAnu93mBn3xeorPlJ6hG7+VhPuJoF2kO1MJ1OG2AsFjNASaG1ljTOMfD9XcBBChE7nQ4eHh7i0dERtlotddqO42C/32cBGrOhlMAnDrlj5Q+GSgOHW7vdxsnJSYzH4xiJRLBYLKqc6oj+sIeO5M1KtoGxoXjFrdlsmhSwLC0tKUN9+qoG3X8OAUgRszBsGHh8fHwLyOU0DPxhe4j/aWdnZzgzM4PT09OYTCaxWq3aIXcZ+FFuxuXlJWxtbcHOzg7W63U8Pz/Hk5MT3NzcxO3tbdzf38erqyskG/W9VqsBHZo5FPLpMx/KrAAZxKU5NjamwimVSpjNZk14fBB7e3t2yEA5ROscXrKHDyn+U57Y3d312DAUCvEThOVyGXO5nAFMTU3hwcEBf8dgMKhs8vm8r3P4i4Dj6rZcX18/50kKy+VdZfdCoQCZTMYAo9EoNhoNsG0WFhaUd8SYk6s3oi/2Oy7WlZUVlx4Bb3l5mQsZaBOgPqyurgIfwMXFBWxsbHA6/PX1dYfzTK1sHgfzQmio/XzpZMPQVfMkZ7qVZb04F6D7aaDdbjdH+fhu3xauMRa535IzE6bNsP4CRsRb6j+g/gvSddK/LXiXS4NPk4bjw+u4rv8C5lC4pDZ5rvwAAAAASUVORK5CYII=" alt="DevTimes" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/c9a164741da1db2837cd1e6d841a84fb/91664/main-logo.png 1x,
/static/c9a164741da1db2837cd1e6d841a84fb/ad39b/main-logo.png 1.5x,
/static/c9a164741da1db2837cd1e6d841a84fb/183c2/main-logo.png 2x" /><img loading="lazy" width="30" height="30" srcset="/static/c9a164741da1db2837cd1e6d841a84fb/91664/main-logo.png 1x,
/static/c9a164741da1db2837cd1e6d841a84fb/ad39b/main-logo.png 1.5x,
/static/c9a164741da1db2837cd1e6d841a84fb/183c2/main-logo.png 2x" src="/static/c9a164741da1db2837cd1e6d841a84fb/91664/main-logo.png" alt="DevTimes" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div></a><div class="style__NavWrapper-sc-1nu4t1g-2 jnMIuM"><ul class="style__NavMenu-sc-1nu4t1g-3 hqRQjv"><li class="style__NavMenuItem-sc-1nu4t1g-4 jMoVC"><a class="style__NavLink-sc-1nu4t1g-5 fiqFtq" href="/tag/web">Web</a></li><li class="style__NavMenuItem-sc-1nu4t1g-4 jMoVC"><a class="style__NavLink-sc-1nu4t1g-5 fiqFtq" href="/tag/python">Python</a></li><li class="style__NavMenuItem-sc-1nu4t1g-4 jMoVC"><a class="style__NavLink-sc-1nu4t1g-5 fiqFtq" href="/tag/ml-dl">ML-DL</a></li><li class="style__NavMenuItem-sc-1nu4t1g-4 jMoVC"><a class="style__NavLink-sc-1nu4t1g-5 fiqFtq" href="/tag/datalake">DataLake</a></li><li class="style__NavMenuItem-sc-1nu4t1g-4 jMoVC"><a class="style__NavLink-sc-1nu4t1g-5 fiqFtq" href="/tag/statistics">Statistics</a></li><li class="style__NavMenuItem-sc-1nu4t1g-4 jMoVC"><a class="style__NavLink-sc-1nu4t1g-5 fiqFtq" href="/tag/tip">Tips</a></li><li class="style__NavMenuItem-sc-1nu4t1g-4 jMoVC"><a class="style__NavLink-sc-1nu4t1g-5 fiqFtq" href="/page">About</a></li></ul><div class="style__SearchContainer-sc-1nu4t1g-6 llrxFq"><ul class="style__NavMenu-sc-1nu4t1g-3 gWKWdg"><li class="style__NavMenuItem-sc-1nu4t1g-4 jMoVC"><button role="button" aria-label="Toggle search" class="style__ToggleSearchButton-sc-1nu4t1g-7 imSJbr"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"></path></svg></button></li></ul></div></div></div></div><main><div style="width:0%" color="#4bc822" class="reading-progress__ReadingProgressBar-i1hf8v-0 JexoF"></div><div class="common__Container-sc-1wbwqlx-0 post__PostContainer-z0x2sj-0 iRWYuq"><div class="post__PostContent-z0x2sj-2 bOhMpF"><article class="post"><header class="post__PostHeader-z0x2sj-4 eMHMJv"><section class="post__PostMeta-z0x2sj-7 fymZCI"><a href="/tag/ml-dl">ML-DL</a><time dateTime="2020-05-24T00:00:00.000Z">24 May, 2020</time></section><h1 class="post__PostTitle-z0x2sj-8 bdTsjL">NLP - 한국어 영화 리뷰 감정분석</h1></header><div class="post__FeaturedImage-z0x2sj-5 eHCGZv gatsby-image-wrapper" style="position:relative;overflow:hidden"><div aria-hidden="true" style="width:100%;padding-bottom:43.5%"></div><img aria-hidden="true" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAACYklEQVQozx2SS2sTYRSG51e4sGrTGE2azH3mm8kkk2SSSZM0qUlMdFG1otQLQsWqINVWrKLipYILETdiwYV4QbEgeMGNVEF3KuIPEPwB/oHHT9cHzvO857xKoGZIZzL4tkWobqespmjU6gwHfTrtJp1Ok7znIGwD4bro2TTq2Aix16ZXnWZQ72Ftt/FMjaBQRhn0pxj0OnhyYeTb6H4R4XuUwwDhmISlIq5joaa3YgpBUndZmp/j/fOPrN56zNLsJTrOkJqWI7dpA0oc+lTzNnHRo+pb1Es+7WZMa7JBPFGVtiEVoTFRMMmb49R8g/VXL/jz6wfP7r3k7MwNFncd5dzOPrFMqMTjW2RcjWajSsGzKLoGQV7gmCpF38XLpcglN+E5Bo40bkvQg2vXubOwwOvVp5zsTtExLXaLIvOTRZTd3QaTgUE3n6Me2DQaMaVykTgUtGoFKtLI1jMEngQJnR2dFiuLF7h44hSr5xbY46UJsgbznZCVvRGKYf8jG2TTKRxLkya6NHOIKjJqKfhvpWbkTJpq6QT9iYjf37/xY32dyweGnO22WJ7ez8q+LrdneihRwcOd7CFqMfWoTGQ75NQcgbyXsHW2JJOY2RSWmsbOJvDlp39++syXtSfcnRtyrH6coT7LmVjl2s4WilsqkXF90qbNVs1ksxGS8CPccoUxN0QrVNBEntGszjZVRUQTvHn0jqe373N++iD7giFHwgpX+hYLcQll1PAoRBWmBl1Eo82oX/sPMGWvMokRtLGNGCn5lFwCT03KaqmsPXzLh7WvLB++ymK/yemG4ObQ51A74i/iik3FpHalwgAAAABJRU5ErkJggg==" alt="" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/3081b292a1f8afbb61de9dd1ab205863/dc47e/cover.png 200w,
/static/3081b292a1f8afbb61de9dd1ab205863/9f2d5/cover.png 400w,
/static/3081b292a1f8afbb61de9dd1ab205863/c0491/cover.png 460w" sizes="(max-width: 460px) 100vw, 460px" /><img loading="lazy" sizes="(max-width: 460px) 100vw, 460px" srcset="/static/3081b292a1f8afbb61de9dd1ab205863/dc47e/cover.png 200w,
/static/3081b292a1f8afbb61de9dd1ab205863/9f2d5/cover.png 400w,
/static/3081b292a1f8afbb61de9dd1ab205863/c0491/cover.png 460w" src="/static/3081b292a1f8afbb61de9dd1ab205863/c0491/cover.png" alt="" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div><section class="post__StyledPost-z0x2sj-6 ixYMGE post"><p>한국어 데이터에 대해서 텍스트 분석을 해보자. 아래 데이터는 한국어 분석 학습을 위해 다양한 방식으로 사용되고 있다. 여기서는 한글 분석을 위해 Konlpy를 사용하고, 텐서플로 케라스를 이용해 모델을 만들도록 하겠다.</p>
<p><strong>데이터셋 : Naver sentiment movie corpus</strong>
(다운로드 링크 : <a href="https://github.com/e9t/nsmc/">https://github.com/e9t/nsmc/</a>)</p>
<p>NSMC 약어까지 사용할 정도로 많이들 사용하는 데이터 인듯 싶다.</p>
<p><strong>데이터 설명</strong></p>
<p>영화 리뷰 중 영화당 100개의 리뷰이고 총 200,000개의 리뷰(train:15만, test:5만)</p>
<p>1점 ~ 10점 까지의 평점 중에서 중립적인 평점(5점~8점)을 제외하고 분류를 하였다.</p>
<ul>
<li>부정 : 1점 ~ 4점</li>
<li>긍정 : 9점 ~ 10점</li>
</ul>
<p>칼람정보: id, document, label</p>
<ul>
<li>id: 리뷰 아이디</li>
<li>document: 리뷰 내용</li>
<li>label: 레이블 (0: negative, 1: positive)</li>
</ul>
<p>각 파일에 대한 리뷰 갯수</p>
<ul>
<li>ratings.txt: All 20만</li>
<li>ratings_test.txt: 5만</li>
<li>ratings_train.txt: 15만</li>
</ul>
<p>모든 리뷰텍스트는 140자 이내이고, 각 감정 분류는 동일하게 샘플링 된다.(i.e., random guess yields 50% accuracy)</p>
<ul>
<li>10만개의 부정적인 리뷰</li>
<li>10만개의 긍정적인 리뷰</li>
<li>중립적인 리뷰는 제외</li>
</ul>
<h3 id="데이터-준비" style="position:relative;"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A4%80%EB%B9%84" aria-label="데이터 준비 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>데이터 준비</h3>
<p>다운로드 받은 데이터를 pandas를 이용해 읽어보자. 필드 구문이 탭으로 되어 있기 때문에 <code class="language-text">\t</code>로 구분자를 지정해주어야 한다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

train_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"data_naver_movie/ratings_train.txt"</span><span class="token punctuation">,</span> <span class="token string">"\t"</span><span class="token punctuation">)</span>
test_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"data_naver_movie/ratings_test.txt"</span><span class="token punctuation">,</span> <span class="token string">"\t"</span><span class="token punctuation">)</span></code></pre></div>
<h3 id="데이터-전처리" style="position:relative;"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC" aria-label="데이터 전처리 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>데이터 전처리</h3>
<p>데이터를 학습 시키기 위해 전처리를 진행해야 하는데, Konlpy를 이용해 <code class="language-text">형태소 분석 및 품사 태깅</code>을 하도록 하자.</p>
<p>영어의 경우 주어진 단어의 빈도만을 사용해서 처리해도 크게 문제는 없지만 한국어는 영어와는 달리 띄어쓰기로 의미를 구분짓기에는 한계가 있고, 리뷰 특성상 맞춤법이나 띄어쓰기가 제대로 되어있지 않는 경우가 있을 수 있기 때문에 정확한 분류를 위해서는 Konlpy를 이용하는 것이 좋다.</p>
<blockquote>
<p>Konlpy는 띄어쓰기 알고리즘과 정규화를 이용해서 맞춤법이 틀린 문장도 어느 정도 고쳐주면서 형태소 분석과 품사를 태깅해주는 여러 클래스를 제공하고 있다.^^!</p>
</blockquote>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">from</span> konlpy<span class="token punctuation">.</span>tag <span class="token keyword">import</span> Okt
okt <span class="token operator">=</span> Okt<span class="token punctuation">(</span><span class="token punctuation">)</span>
okt<span class="token punctuation">.</span>pos<span class="token punctuation">(</span><span class="token string">u'흔들리는 꽃들 속에서 네 샴푸향이 느껴진거야'</span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">[(&#39;흔들리는&#39;, &#39;Verb&#39;),
 (&#39;꽃&#39;, &#39;Noun&#39;),
 (&#39;들&#39;, &#39;Suffix&#39;),
 (&#39;속&#39;, &#39;Noun&#39;),
 (&#39;에서&#39;, &#39;Josa&#39;),
 (&#39;네&#39;, &#39;Noun&#39;),
 (&#39;샴푸&#39;, &#39;Noun&#39;),
 (&#39;향&#39;, &#39;Noun&#39;),
 (&#39;이&#39;, &#39;Josa&#39;),
 (&#39;느껴진거야&#39;, &#39;Verb&#39;)]</code></pre></div>
<p>테스트 삼아 간단한 문장을 넣고 확인 해보면 이런 형태로 분리를 해주는 것을 알수 있다.</p>
<p>토크나이즈 함수를 만들어 사용하도록 한다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">tokenize</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#형태소와 품사를 join</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>t<span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> okt<span class="token punctuation">.</span>pos<span class="token punctuation">(</span>doc<span class="token punctuation">,</span> norm<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> stem<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span></code></pre></div>
<blockquote>
<p>norm은 정규화, stem은 근어로 표시하기를 나타냄</p>
</blockquote>
<p>리뷰가 null인 경우 위 위 함수에서 오류가 발생할 수 있으니 사전에 null값 확인해보고 빈민자열로 대체하자!</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">train_df<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">any</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#document에 null값이 있다.</span>
train_df<span class="token punctuation">[</span><span class="token string">'document'</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_df<span class="token punctuation">[</span><span class="token string">'document'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">#null값을 ''값으로 대체</span>

test_df<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">any</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
test_df<span class="token punctuation">[</span><span class="token string">'document'</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_df<span class="token punctuation">[</span><span class="token string">'document'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">#null값을 ''값으로 대체</span></code></pre></div>
<p>이제 학습데이터와 테스트데이터를 분석하여 저장해두자.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment">#tokenize 과정은 시간이 오래 걸릴수 있음...</span>
train_docs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>tokenize<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> row<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> row <span class="token keyword">in</span> train_df<span class="token punctuation">.</span>values<span class="token punctuation">]</span>
test_docs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>tokenize<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> row<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> row <span class="token keyword">in</span> test_df<span class="token punctuation">.</span>values<span class="token punctuation">]</span></code></pre></div>
<p>분석결과가 끝났으면 다음과 같은 형태로 데이터가 변형 되었을 것이다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>train_docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>test_docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">([&#39;아/Exclamation&#39;, &#39;더빙/Noun&#39;, &#39;../Punctuation&#39;, &#39;진짜/Noun&#39;, &#39;짜증나다/Adjective&#39;, &#39;목소리/Noun&#39;], 0)
([&#39;굳다/Adjective&#39;, &#39;ㅋ/KoreanParticle&#39;], 1)</code></pre></div>
<p>15만 학습데이터에 분리된 토큰 개수를 살펴보자.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">tokens <span class="token operator">=</span> <span class="token punctuation">[</span>t <span class="token keyword">for</span> d <span class="token keyword">in</span> train_docs <span class="token keyword">for</span> t <span class="token keyword">in</span> d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"토큰개수:"</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">토큰개수: 2159921</code></pre></div>
<p>이제 이데이터를 가지고 nltk를 이용해 전처리를 한다. <code class="language-text">Text</code> 클래스는 문서를 편리하게 탐색할 수 있는 다양한 기능을 제공하고 있다.</p>
<p>여기서는 <code class="language-text">vocab().most_common</code> 매서드를 이용해 데이터가 가장 자주 사용되는 단어를 가져올 때 사용하겠다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> nltk
text <span class="token operator">=</span> nltk<span class="token punctuation">.</span>Text<span class="token punctuation">(</span>tokens<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'NMSC'</span><span class="token punctuation">)</span>

<span class="token comment">#토큰개수</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>text<span class="token punctuation">.</span>tokens<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#중복을 제외한 토큰개수</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>text<span class="token punctuation">.</span>tokens<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#출력빈도가 높은 상위 토큰 10개</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>text<span class="token punctuation">.</span>vocab<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">2159921
49894
[(&#39;./Punctuation&#39;, 67778), (&#39;영화/Noun&#39;, 50818), (&#39;하다/Verb&#39;, 41209), (&#39;이/Josa&#39;, 38540), (&#39;보다/Verb&#39;, 38538), (&#39;의/Josa&#39;, 30188), (&#39;../Punctuation&#39;, 29055), (&#39;가/Josa&#39;, 26627), (&#39;에/Josa&#39;, 26468), (&#39;을/Josa&#39;, 23118)]</code></pre></div>
<h3 id="데이터-탐색" style="position:relative;"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%83%90%EC%83%89" aria-label="데이터 탐색 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>데이터 탐색</h3>
<p>출력빈도가 높은 상위 토큰 10개를 matplotlib을 이용해 그래프로 확인해보자.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token operator">%</span>matplotlib inline</code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> font_manager<span class="token punctuation">,</span> rc
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
text<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span></code></pre></div>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1180px;"
    >
      <a
    class="gatsby-resp-image-link"
    href="/static/5e6ea63c51a3bda8081412b5c6840e56/c83ae/korea_movie_review_plot.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 55.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABRElEQVQoz62Ry0rDUBCGz8Y3qKnP5AO4bqK+mN12Ebwgbow0uBRRm3vQopvSbsTYnMuckzgTm1KkBIQe+Pnn/DP5mCTs8tztFcsy5Jx/CCHe0Kebwmz6N9uiV5yblWV5w+7HnsUliHoHBwAidn11YUmlvkoJtdbaKAAD/xcQUCn1zMZ3t/sIKQSY2hhdUQ/Bjdq6KyMn6Ar4ws6GwwNjTCExWwpVmWZoPbjt4W6g67p9bBQUFFxWpVC16d6mG+j7fq8FolffCCVJBfT6tHGlNVTUozuprTcyvQaORqM+Bp+/A6BIAv/SkktV4LpcKMAS8Ds3Pd24xmvjoIkGIFfAR+Z5nlXv6Egp3xlS9xaLxVEYhid5ng+yLBukaWqn6EmS2FmaOFkSO3EcO2FEirBObKztSRAcB0FIuf3wNDmdzeeHbNfnB3BY7E9yM0ftAAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="png"
        title="png"
        src="/static/5e6ea63c51a3bda8081412b5c6840e56/c83ae/korea_movie_review_plot.png"
        srcset="/static/5e6ea63c51a3bda8081412b5c6840e56/5a46d/korea_movie_review_plot.png 300w,
/static/5e6ea63c51a3bda8081412b5c6840e56/0a47e/korea_movie_review_plot.png 600w,
/static/5e6ea63c51a3bda8081412b5c6840e56/c83ae/korea_movie_review_plot.png 1180w"
        sizes="(max-width: 1180px) 100vw, 1180px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
  </a>
    </span></p>
<p>모델을 만들기 위해 백터화를 해야 하는데, 자주 사용되는 토큰 10000개를 사용해 데이터를 백터화 하자.(원 핫 인코딩 대신 CountVectorization을 사용)</p>
<p>문서 집합에서 단어 토큰을 생성하고 각 단어의 수를 세어 BOW(Bag of Words) 인코딩한 벡터를 만드는 역할을 한다.</p>
<p>시간이 오래 걸리므로 100개만 해보자...</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">FREQUENCY_COUNT <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">;</span> <span class="token comment">#시간적 여유가 있다면 10000개를 해보도록~</span></code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">selected_words <span class="token operator">=</span> <span class="token punctuation">[</span>f<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> f <span class="token keyword">in</span> text<span class="token punctuation">.</span>vocab<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>most_common<span class="token punctuation">(</span>FREQUENCY_COUNT<span class="token punctuation">)</span><span class="token punctuation">]</span></code></pre></div>
<p>이 과정은 데이터 양이 큰 만큼 시간이 오래 걸리기 때문에 이 작업을 반복하지 않도록 태깅을 마친 후에는 json파일로 저장하는 것도 좋은 방법이다.</p>
<p>문서에서 상위로 선택된 단어들중 몇개가 포함이 되는지를 알아야 한다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment">#단어리스트 문서에서 상위 10000개들중 포함되는 단어들이 개수</span>
<span class="token keyword">def</span> <span class="token function">term_frequency</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>doc<span class="token punctuation">.</span>count<span class="token punctuation">(</span>word<span class="token punctuation">)</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> selected_words<span class="token punctuation">]</span></code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment">#문서에 들어가는 단어 개수</span>
x_train <span class="token operator">=</span> <span class="token punctuation">[</span>term_frequency<span class="token punctuation">(</span>d<span class="token punctuation">)</span> <span class="token keyword">for</span> d<span class="token punctuation">,</span>_ <span class="token keyword">in</span> train_docs<span class="token punctuation">]</span>
x_test <span class="token operator">=</span> <span class="token punctuation">[</span>term_frequency<span class="token punctuation">(</span>d<span class="token punctuation">)</span> <span class="token keyword">for</span> d<span class="token punctuation">,</span>_ <span class="token keyword">in</span> test_docs<span class="token punctuation">]</span></code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment">#라벨(1 or 0)</span>
y_train <span class="token operator">=</span> <span class="token punctuation">[</span>c <span class="token keyword">for</span> _<span class="token punctuation">,</span>c <span class="token keyword">in</span> train_docs<span class="token punctuation">]</span>
y_test <span class="token operator">=</span> <span class="token punctuation">[</span>c <span class="token keyword">for</span> _<span class="token punctuation">,</span>c <span class="token keyword">in</span> test_docs<span class="token punctuation">]</span></code></pre></div>
<p>이렇게 하면 x축 데이터에는 단어들이 빈도수 정보?, y축에는 분류 결과를 깔끔하게 정리할 수 있다.</p>
<p>이제 데이터를 float로 형 변환 시켜주면 데이터 전처리 과정은 끝~~</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">x_train <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span>
x_test <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span>

y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span>
y_test <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>y_test<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span></code></pre></div>
<h3 id="데이터-모델링" style="position:relative;"><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%AA%A8%EB%8D%B8%EB%A7%81" aria-label="데이터 모델링 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>데이터 모델링</h3>
<p>텐서플로 케라스를 이용해 모델을 만들어 보자.</p>
<p>레이어 구성은 두개의 Danse층은 64개의 유닛을 가지고 활성함수는 relu를 사용하고, 마지막층은 sigmoid 활성화 함수를 사용해 긍정 리뷰일 확률을 출력할 것이다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

<span class="token comment">#레이어 구성</span>
model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span>FREQUENCY_COUNT<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div>
<p>손실 함수는 binary_crossentropy, RMSprop 옵티마이저를 통해 경사하강법을 진행</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment">#학습 프로세스 설정</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>binary_crossentropy<span class="token punctuation">,</span>
    metrics<span class="token operator">=</span><span class="token punctuation">[</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>binary_accuracy<span class="token punctuation">]</span>
    <span class="token punctuation">)</span></code></pre></div>
<p>배치 사이즈는 512, 에포크는 10번으로 학습</p>
<p>자, 이제 학습을 시켜 모델을 만들어 보자! 먼가 있어 보이는 진행률 상태를 볼 수 있다.:)</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment">#학습 데이터로 학습</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">WARNING:tensorflow:From C:\Users\DESKTOP\.conda\envs\nlp\lib\site-packages\tensorflow\python\ops\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Epoch 1/10
150000/150000 [==============================] - 17s 115us/sample - loss: 0.5611 - binary_accuracy: 0.6948s - loss: 0.6134 - binary_accuracy:  - ETA: 21s - loss: 0.6108 - binary_accuracy: 0. - ETA: 20s -  - ETA: 15s - loss: 0.5957 - binary_accuracy: 0.67 - ETA: 15s - loss: 0.5955 - binary_accuracy: 0.67 - ETA: 15s - loss: 0.5951 - binary_accura - ETA: 14s - loss: 0.5930 - binary_accuracy: 0. - ETA: 14s - loss: 0.5923 - binary_accuracy:  - ETA: 13s - loss: 0.5911 - binary_accura - ETA: 8s - loss: 0.5785 - binary_accuracy: 0. - ETA: 8s - loss: 0.5771 - binary_accuracy: 0.68 - ETA: 8s - loss: 0.5764 - binary_accuracy:  - ETA: 7s - loss: 0.5751 - binary_accura - ETA: 6s - loss: 0.5727 - binary_accuracy: - ETA: 6s - loss: 0.5713 - binary_accuracy: 0.6 - ETA: 5s - loss: 0.5708 - binary_a - ETA: 4s - loss: 0.5685 - binary_accuracy: - ETA: 4s - loss: 0.5676 - binary_accuracy: 0.691 - ETA: 4s - loss: 0.5674 - binary_a - ETA: 2s - loss: 0.5652 - binary_accuracy: 0.692 - ETA: 2s - loss: 0.5651 - binary_accurac - ETA: 1s - loss: 0.5639 - binary_accuracy - ETA: 1s - loss: 0.5628 - binary_accuracy: 0.694 - ETA: 1s - loss: 0.5627 - binary_accuracy: 0.694 - ETA: 1s - loss: 0.5626 - binary_accuracy: 0.694 - ETA: 1s - loss: 0.5623 - binary_accuracy: 0.694 - ETA: 1s - loss: 0.5623 - binary_accuracy:  - ETA: 0s - loss: 0.5615 - binary_accuracy: 0.69 - ETA: 0s - loss: 0.5612 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.5613 - binary_accuracy: 0.6
Epoch 2/10
150000/150000 [==============================] - 12s 83us/sample - loss: 0.5313 - binary_accuracy: 0.71254s - loss: 0.5221 - binary_ac - ETA: 15s - loss: 0.5345 - binary_accuracy:  - ETA: 16s - loss: 0.5377 - binary_accuracy - ETA: 14s - loss - ETA: 13s - lo - ETA: 7s - loss: 0.5341 - binary_accuracy: 0.71 - ETA: 7s -  - ETA: 4s - loss: 0.5340 - binary_accur - ETA: 3s - loss: 0.5335 - binary_accuracy: 0.71 - ETA: 3s - loss: 0.5335 - binary_ - ETA: 2s - loss: 0.5325 - binary_accuracy: 0 - ETA: 1s - loss: 0.
Epoch 3/10
150000/150000 [==============================] - 13s 86us/sample - loss: 0.5236 - binary_accuracy: 0.7170s - loss: 0.5284 - binary_accuracy - ETA: 10s - los - ETA: 9s - loss: 0.5255 - binary_accurac - ETA: 9s - loss: 0.5250 - binary_accuracy: 0. - ETA: 9s - loss: 0.5255 - binary_accuracy: 0.716 - ETA: 9s - loss: 0.5254 - binary - ETA: 8s - loss: 0.5247 - binary_acc - ETA: 7s - loss: 0.5251 - binary_accuracy: 0.7 - ETA: 7s - loss: 0.5252 - binary_accuracy: 0.71 - ETA: 7s - loss: 0.5249 - binary_accuracy: 0.716 - ETA: 7s - loss: 0.5248 - binary_accuracy: 0.7 - ETA: 6s - loss: 0.5245 - binary_accuracy: - ETA: 6s - loss: 0.5246 - binary_accuracy: 0 - ETA: 5s - loss: 0.5247 - bina - ETA: 5s - loss: 0.5249 - b - ETA: 3s - loss: 0.5246 - binary_ac - ETA: 2s - loss: 0.5246 - binary_ac - ETA: 2s - loss: 0.5244 - binary_accuracy: 0.71 - ETA: 2s - loss: 0.5244 - binary_accuracy: - ETA: 1s - loss: 0.5242 - binary_accur - ETA: 1s - loss: 0.5243 - binary_accuracy: 0 - ETA: 0s - loss: 0.5243 - binary_accuracy - ETA: 0s - loss: 0.5239 - binary_accuracy: 0.7 - ETA: 0s - loss: 0.5237 - binary_accuracy: 0.7 - ETA: 0s - loss: 0.5236 - binary_accuracy: 0.71
Epoch 4/10
150000/150000 [==============================] - 13s 89us/sample - loss: 0.5179 - binary_accuracy: 0.7219s - loss: 0.5201 - binary_accuracy: 0 - ETA: 8s - loss: 0.5211 - binary_a - ETA: 9s - loss: 0.5208 - binary_accuracy: 0.721 - ETA: 8s - loss: 0.5201 - binary_accuracy: 0.72 - ETA: 8s - loss: 0.5210 - - ETA: 7s - loss: 0.5180 - binary_ac - ETA: 7s - loss: 0.5187 - binar - ETA: 6s - loss: 0.5186 - binary_accura - ETA: 6s - loss: 0.5183 - binary_accuracy: 0.7 - ETA: 6s - loss: 0.5182 - binary_ac - ETA: 5s - loss: 0.5179 - binary_accuracy: 0.723 - ETA: 5s - loss: 0.5179 - binary_accurac - ETA: 4s - loss: 0.5187 - binary_accuracy: 0.722 - ETA: 4s - lo
Epoch 5/10
150000/150000 [==============================] - 13s 87us/sample - loss: 0.5132 - binary_accuracy: 0.72531s - loss: 0.5093 - binary_accuracy: 0.72 - ETA: 11s - ETA: 9s - loss: 0.5156 - binary_accuracy: 0.7 - ETA: 9s - loss: 0.5163 - binary_accuracy:  - ETA: 9s - loss: 0.5154 - binary_accurac - ETA: 8s - loss: 0.5164 - bin - ETA: 7s - loss: 0.5156 - binary - ETA: 6s - loss: 0.5168 - binary_accuracy: 0. - ETA: 6s - loss: 0.5163 - binary_accuracy: 0.72 - ETA: 6s - loss: 0.5160 - binary_accur - ETA: 5s - loss: 0.5154 - binary_accuracy: 0.723 - ETA: 5s - loss: 0.5153 - binary_a - ETA: 4s - los - ETA: 2s - loss: 0.5136 - binary_acc - ETA: 1s - loss: 0.5135 - binary_accuracy: 0.724 - ETA: 1s - loss: 0.5134 - binary_accuracy - ETA: 1s - loss: 0.5132 - binary_ac
Epoch 6/10
150000/150000 [==============================] - 13s 87us/sample - loss: 0.5094 - binary_accuracy: 0.72850s - loss: 0.4971 - binary_accuracy: 0.73 - ETA: 11s - loss: 0.5000 - binary_ - ETA: 9s - loss: 0.5043 - binary_accuracy: - ETA: 10s - loss: 0.5081 - binary_accuracy:  - ETA: 9s - loss: 0.5086 - binary_a - ETA: 9s - loss: 0.5106 - binary_accuracy: 0 - ETA: 9s - loss: 0.5111 - binary_accuracy: 0.72 - ETA: 9s - loss: 0.5112 - binary_accuracy:  - ETA: 9s - loss: 0.5122 - binary_accuracy: 0.724 - ETA: 9s - loss: 0.5122 - binary_accuracy:  - ETA: 8s - loss: 0.5114 - binary_accuracy: 0. - ETA: 8s - loss: 0.5115 - binary_accuracy: 0. - ETA: 8s - loss: 0.5118 - binary_accuracy: 0 - ETA: 8s - loss: 0.5111 - binary_accuracy: 0.725 - ETA: 8s - loss: 0.5114 - - ETA: 6s - loss: 0.5099 - binary_accuracy - ETA: 6s - loss: 0.5108 - binary_accuracy - ETA: 5s - loss: 0.5100 - binary_accuracy: 0.726 - ETA: 5s - loss: 0.5102 - binary_acc - ETA: 4s - loss: 0.5102 - binary_accurac - ETA: 4s - loss: 0.5102 - binary_accuracy: 0.7 - ETA: 4s - l - ETA: 1s - loss: 0.5102 - binary_accu - ETA: 1s - loss: 0.5098 - bi - ETA: 0s - loss: 0.5094 - binary_accuracy: 0.72
Epoch 7/10
150000/150000 [==============================] - 12s 79us/sample - loss: 0.5064 - binary_accuracy: 0.73061s - loss: 0.5050 - binary_accura - ETA: 9s - loss: 0.5096 - binary_accuracy: 0.72 - ETA: 9s - loss: 0.5090 - binary_accuracy - ETA: 8s - loss: 0.5083 - binary_accuracy: 0.7 - ETA: 8s - loss: 0.5082 - binary_accuracy: 0.7 - ETA: 8s - loss: 0.5083 - binary_accur - ETA: 7s - loss: 0.5085 - binary_accuracy: 0 - ETA: 6s - loss: 0.5079 - binary_a - ETA: 5s - loss: 0.5079 - binary_accuracy: 0. - ETA: 5s - loss: 0.5080 - binary_accuracy:  - ETA: 5s - loss: 0.5078 - binary_accuracy - ETA: 4s - loss: 0.5081 - binary_accuracy: 0 - ETA: 4s - loss: 0.5080 - binary_accuracy: 0.730 - ETA: 4s - loss: 0.5080 - binary_accuracy: 0.730 - ETA: 4s - loss: 0.5078 - binary_accuracy:  - ETA: 4s - loss: 0.5072 - binary_accuracy: 0 - ETA: 3s - loss: 0.5072 - binary_ - ETA: 2s - lo - ETA: 0s - loss: 0.5064 - binary_accuracy: 0.730
Epoch 8/10
150000/150000 [==============================] - 13s 85us/sample - loss: 0.5037 - binary_accuracy: 0.73210s - loss: 0.5053 - binary_acc - ETA: 9s - loss: 0.5045 - binary_accuracy:  - ETA: 9s - loss: 0.5024 - binary_accu - ETA: 8s - loss: 0.5013 - binary_accu - ETA: 8s - loss: 0.5014 - binary_accuracy: 0.73 - ETA: 8s - loss: 0.5007 - binar - ETA: 6s - loss: 0.5013 - binary_a - ETA: 6s - loss: 0.5016 - binary_accuracy:  - ETA: 6s - loss: 0.5019 - binary_accuracy: 0.73 - ETA: 5s - loss: 0.5019 - binary_accuracy: 0 - ETA: 5s - loss: 0.5023 - binary_accuracy: 0.73 - ETA: 5s - loss: 0.5021 - binary_accuracy: 0.73 - ETA: 5s - l - ETA: 3s - loss: 0.5027 - ETA: 2s - loss: 0.5036 - binary_accuracy:  - ETA: 2s - loss: 0.5033 - binary_accuracy: 0.732 - ETA: 2s - loss: 0.5033 - binary_accuracy: 0.73 - ETA: 2s - loss: 0.5034 - binary_accur - ETA: 1s - loss: 0.5035 - binary_accuracy:  - ETA: 0s - loss: 0.5033 - binary_accuracy:  - ETA: 0s - loss: 0.5035 - binary_acc
Epoch 9/10
150000/150000 [==============================] - 13s 85us/sample - loss: 0.5015 - binary_accuracy: 0.7337s - loss: 0.5023 - binary_accu - ETA: 13s - loss: 0.4956 - binary_accuracy: 0. - ETA: 14s - loss: 0.4949 - binary_accu - ETA: 15s - loss: 0.4938 - binary_accuracy: 0. - ETA: 15s - loss: 0.4977 - binary_accuracy: 0.73 - ETA: 15s - loss: 0.4981 - binary_accuracy: 0. - ETA: 14s - loss:  - ETA: 12s - loss: 0.4989 - binary_accuracy - ETA: 12s - loss: 0.4992 - binary_accuracy - ETA: 11s - loss: 0.4990 - binary_ - ETA: 10s - loss: 0.4982 - binary_accuracy: 0.73 - ETA: 10s - loss: 0.4982 - binar - ETA: 9s - loss: 0.4997 - binary_accuracy: 0. - ETA: 9s - loss: 0.4997 - binary_accuracy: 0 - ETA: 8s - loss: 0.4996 - binary_accuracy: 0.7 - ETA: 8s - loss: 0.4997 - binary - ETA: 7s - loss: 0.5011 - bina - ETA: 6s - loss: 0.5014 - binary_accuracy: 0.7 - ETA: 6s - loss: 0.5011 - binary_ - ETA: 4s - loss: 0.5016 - binary_accuracy: 0.733 - ETA: 4s - loss: 0.5017 - binary_accurac - ETA: 4s - loss: 0.5018 - binary_ac - ETA: 2s - loss: 0.5022 - binary_accuracy: 0.7 - ETA: 2s - loss: 0.5023 - binary_accuracy: 0.73 - ETA: 2s - loss: 0.5021 - binary_accuracy: - ETA: 1s - loss: 0.5018 - binary_accuracy: 0 - ETA: 1s - loss: 0.5019 - binary_accuracy - ETA: 1s - loss: 0.5018 - binary_accuracy: 0.73 - ETA: 1s - loss: 0.5018 - binary_accuracy: 0.7 - ETA: 1s - loss: 0.5017 - binary_a
Epoch 10/10
150000/150000 [==============================] - 14s 91us/sample - loss: 0.4995 - binary_accuracy: 0.73620s - loss: 0.4948 - binary_accuracy:  - ETA: 14s - loss: 0.4965 - binary_accura - ETA: 14s - loss: 0.4980 - binary_accu - ETA: 12s - loss: 0.4973 - binary_accuracy - ETA: 12s - loss: 0.5014 - binar - ETA: 12s - loss: 0.4992 - binary_accuracy - ETA: 12s - loss: 0.4996 - binary_accuracy:  - ETA: 12s - loss: 0.5001 - binary_accuracy: 0.73 - ETA: 12s - loss: 0.5003 - binary_accura - ETA: 11s - loss: 0.5011 - b - ETA: 9s - loss: 0.5027 - binary_accuracy:  - ETA: 9s - loss: 0.5026 - binary_accuracy - ETA: 8s - loss: 0.5013 - binary_accur - ETA: 8s - loss:  - ETA: 6s - loss: 0.5013 - binary_ - ETA: 5s - loss: 0.5006 - binary_ac - ETA: 4s - loss: 0.4997 - binary_accurac - ETA: 4s - loss: 0.5001 - binary_ac - ETA: 3s - loss: 0.5001 - b - ETA: 1s - loss: 0.4989 - binary_accuracy: 0.736 - ETA: 1s - loss: 0.4989 - binary_accuracy: 0.736 - ETA: 1s - loss: 0.4988 - binary_accuracy: 0.736 - ETA: 1s - loss: 0.4989 - binary_accurac - ETA: 1s - loss: 0.4991 - binary_accuracy: 0. - ETA: 0s - loss: 0.4993 - binary_accura - ETA: 0s - loss: 0.4995 - binary_accuracy: 0.73

&lt;tensorflow.python.keras.callbacks.History at 0x1967af62ac8&gt;</code></pre></div>
<h3 id="모델-평가" style="position:relative;"><a href="#%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80" aria-label="모델 평가 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>모델 평가</h3>
<p>학습데이터를 이용해 모델 학습이 끝났다면 테스트 데이터를 가지고 모델을 평가해보자.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">results <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">50000/50000 [==============================] - 12s 234us/sample - loss: 0.5198 - binary_accuracy: 0.7184s - loss: 0.5197 - b - ETA: 11s - loss: 0.5199 - binary_accuracy: 0.  - ETA: 1s - loss: 0.5198 - b</code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment">#loss: 0.5, acc: 0.7</span>
results</code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">[0.5197769028568268, 0.71842]</code></pre></div>
<blockquote>
<p>여기서는 100건으로 했기때문에 좀 낮은 71%의 정확도가 나왔다. 아마 사용한 토큰수를 100개가 아닌 10000개로 했다면 85%정도의 정확도를 확인할 수 있을 것이다.</p>
</blockquote>
<p>팁으로 힘들게 만든 모델을 아래와 같이 저장해두고 나중에 로드해서 사용할수 있으니 꼭 알아두자.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment">#모델을 저장해둘수도 있다.</span>
model<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">'movie_review_model.h5'</span><span class="token punctuation">)</span>

<span class="token comment"># 모델 불러오기</span>
<span class="token comment">#from keras.models import load_model</span>
<span class="token comment">#model = load_model('movie_review_model.h5')</span></code></pre></div>
<h3 id="결과-예측하기" style="position:relative;"><a href="#%EA%B2%B0%EA%B3%BC-%EC%98%88%EC%B8%A1%ED%95%98%EA%B8%B0" aria-label="결과 예측하기 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>결과 예측하기</h3>
<p>이제 리뷰 문자열을 받아 바로 결과를 예측하는 함수를 만들어 보자</p>
<p>데이터 형태를 맞추기 위해 np.expand_dims 매서드를 이용해 array의 축을 확장 시켜주어야 한다.</p>
<p>최종 확률이 0.5 이상이면 긍정, 그렇지 않으면 부정이라고 예측을 하겠다.</p>
<p>대략 테스트를 먼저 해보고...</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">review <span class="token operator">=</span> <span class="token string">"아주 재미 있어요"</span>
token <span class="token operator">=</span> tokenize<span class="token punctuation">(</span>review<span class="token punctuation">)</span>
token</code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">[&#39;아주/Noun&#39;, &#39;재미/Noun&#39;, &#39;있다/Adjective&#39;]</code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">tf <span class="token operator">=</span> term_frequency<span class="token punctuation">(</span>token<span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">data <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>tf<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token builtin">float</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">0.9102853536605835</code></pre></div>
<p>테스트한 로직을 함수화해서 사용하자.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">predict_review</span><span class="token punctuation">(</span>review<span class="token punctuation">)</span><span class="token punctuation">:</span>
    token <span class="token operator">=</span> tokenize<span class="token punctuation">(</span>review<span class="token punctuation">)</span>
    tfq <span class="token operator">=</span> term_frequency<span class="token punctuation">(</span>token<span class="token punctuation">)</span>
    data <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>tfq<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    score <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span>score <span class="token operator">></span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>review<span class="token punctuation">}</span></span><span class="token string"> ==> 긍정 (</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">round</span><span class="token punctuation">(</span>score<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">%)"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>review<span class="token punctuation">}</span></span><span class="token string"> ==> 부정 (</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">round</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>score<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">%)"</span></span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">predict_review<span class="token punctuation">(</span><span class="token string">"재미 정말 없어요"</span><span class="token punctuation">)</span></code></pre></div>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">재미 정말 없어요 ==&gt; 부정 (93%)</code></pre></div>
<p>이제 리뷰텍스트 만으로 긍정인지 혹은 부정인지를 어느정도 판단 할 수 있게 되었다.</p>
<p>지금까지 영화리뷰 데이터를 통해서 감정분석을 해보았는데 상품, 게임, 음식등의 사용자 의견이 담긴 데이터를 잘 모아서 활용한다면 다양한 곳에 활용할 수 있을 것이다.</p></section><hr/><div></div><footer class="post__PostFooter-z0x2sj-9 gDLYpk"><p>Published under <span><a class="post__FooterTagLink-z0x2sj-10 hKDtNq" href="/tag/ml-dl">ML-DL</a>, </span><span><a class="post__FooterTagLink-z0x2sj-10 hKDtNq" href="/tag/ml">ML</a>, </span><span><a class="post__FooterTagLink-z0x2sj-10 hKDtNq" href="/tag/nlp">NLP</a></span> on <time dateTime="2020-05-24T00:00:00.000Z">24 May, 2020</time>.</p></footer></article></div><div class="post__LeftSidebar-z0x2sj-1 guoPGM"><div class="post__TocWrapper-z0x2sj-3 hyzxOc"><nav class="toc__StyledNav-dzz3d3-0 kAaKev toc"></nav></div></div><button role="button" aria-label="Toggle table of contents" class="post__ToggleTocButton-z0x2sj-14 ewrmMm"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M432 416H16a16 16 0 0 0-16 16v32a16 16 0 0 0 16 16h416a16 16 0 0 0 16-16v-32a16 16 0 0 0-16-16zm0-128H16a16 16 0 0 0-16 16v32a16 16 0 0 0 16 16h416a16 16 0 0 0 16-16v-32a16 16 0 0 0-16-16zm0-128H16a16 16 0 0 0-16 16v32a16 16 0 0 0 16 16h416a16 16 0 0 0 16-16v-32a16 16 0 0 0-16-16zm0-128H16A16 16 0 0 0 0 48v32a16 16 0 0 0 16 16h416a16 16 0 0 0 16-16V48a16 16 0 0 0-16-16z"></path></svg></button></div><section class="post__PostAddition-z0x2sj-11 dWgKtp"><div class="common__Container-sc-1wbwqlx-0 post__PostAdditionContent-z0x2sj-12 kWRivk"><div class="post__BioWrapper-z0x2sj-13 rrUdK"><section class="bio__StyledBio-j3ch0c-0 gmpFBk"><div class="avatar__StyledAvatar-sc-1papyes-0 cCbMYU gatsby-image-wrapper" style="position:relative;overflow:hidden;display:inline-block;width:70px;height:70px"><img aria-hidden="true" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAAEfUlEQVQ4y1WUbWxTVRjHL4YPLL4wYtwYg9FtdKwY5EUjwwDb4lxAEA1kycxUTFA0mChiNFPDNMNgVEwQiEJA3GQbrBvrqFBwBUb3ytp1YwO2MbqXru3t69Z262b0y897i53thyf3nHPv+d3/ef7PcwSXU8QpOpCfbpczHPLYYbcT8I9jc4h03e7F3NVNIOAnGJjAFfV9ZH+EIUSDIiE67ExPT9He1s7LW18n69lcslZnsWf3+zTob+D3T4Q3u5z/AyNPIRrkcT/8ICgpOVtWwZqMNSQ9lsjiBUkoFylIS05BmZZJ6cHvmJkJ4ZH2RGAxQI/bFQ55MTQVRHvpKqqUTFTJaSieWsrShBSSn0wmMzWDjNRlJMQnsG/f57g9njA0AgwfWQZ5Pe6wQp/XjdVmZ/uWHbz2Yg5PK5aTnqhAuTCNdEmhYlEKqckKUhIXEzc3nl/LzjE1GQinKJI6IaJOljsj5a229iIvLF/Lm1u3s161lizValRJy1EmKlmVtgKVYhkrlZnME+LYVbSbUGgyDIykTYg+7sx0iGNHfmZnTi57CnfyxkubKVyfR3HhLo5/tJ8f9r7H0QMfUrL3bVRLUnlGuZJhiwWfzxMWFAOUJ8FggLqaajavX8emFav5/XApRm0FFn0dYze1DOir8Q83ovn1e3bk5ZC3cQO3WtvDJsqC5NTFAqUXt1oM5K5ag/rEjzj7m2lXn8GsLqP/Ug1N5ScxXa7CqK9iR042u98qZKCvj4kJX3h/GOjzemZNmZoMYuowUpCfj99mpP2PCs58WUKXupyh62ouHPqW06UlTFga+ezdIgq2vcpk0D9bJXIIMkwOeRKQCvbBwADHS4sJ2jpwm29iNVxhfKSTgPSDoRYddy+r+cth5Ng3+zn4RYnUAKFZdTFHliey2nEpwU11Zdi76/GZGxHbriH23sTRo8dh+hO38QaBwUbOHT3A/Z5OJiQRnqjmiClsuVO8Xi/WwW4c3Rq8XTrEVkmV7jxdmnKGr19gpLEeq1FN57UKyQjZWVdM2woRQ6Lbz+l0YbtrwNd7CUuzlnu6i9zR1vGgpR7bLQ2D7WpGLf3SqTwxF0u4U6JvmIdj6aYRRcSRfkaaKhky1HJPU4O5shJLiwZLUwV9HTpcbk/MTSMXd7iXI4sOuw27FLYxq1SPfnq7TXRfOY2np15yuIbBq2ps5npuN/zC0J2Wh8D/QNEhyAB54JX62O/3MR3y09Bwgy3biugzVDLSUkXb+ZPoTx3DrDvF/ebfGL7bisvlxm4bmwXJguQQJoPjUt5EOk2dVFdr+ODjr3l0YRaqdQXY7hnw3K7lztUzNJ/7iQetVZLDlzlx5DCGpjb++TuETYKOSaIicGHfJ6VszCsiKTWbR+LXIiRsZG5SNunPF9Bj7mR8yCgZUYe1VY3VpGZaqs9Piw+RmpGLVquTjBGl+vXNqhSEJ55jzoJ1xCVuYP6STcSn5/N4Wj7zkrPRXzcQCnpxDPfjGOhg1HQB72gPxV8dQZiTQdz8VeS/8g7lZ2sYHR1GFO38C4HH48JXOTvxAAAAAElFTkSuQmCC" alt="winuss" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/f39bad8c29c07a4d4c5b9eb67697ccb3/75aa5/blogger.png 1x,
/static/f39bad8c29c07a4d4c5b9eb67697ccb3/97b93/blogger.png 1.5x,
/static/f39bad8c29c07a4d4c5b9eb67697ccb3/9adda/blogger.png 2x" /><img loading="lazy" width="70" height="70" srcset="/static/f39bad8c29c07a4d4c5b9eb67697ccb3/75aa5/blogger.png 1x,
/static/f39bad8c29c07a4d4c5b9eb67697ccb3/97b93/blogger.png 1.5x,
/static/f39bad8c29c07a4d4c5b9eb67697ccb3/9adda/blogger.png 2x" src="/static/f39bad8c29c07a4d4c5b9eb67697ccb3/75aa5/blogger.png" alt="winuss" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div><h3 class="bio__AuthorName-j3ch0c-2 kStElJ">winuss</h3><p class="bio__AuthorDescription-j3ch0c-1 frcJlw">Every end is a <strong>new beginning</strong>.
            <a href="https://devtimes.com" rel="noopener" target="_blank">devtimes.com</a></p><ul class="social-channel-list__StyledSocialChannels-z1p8fq-0 cNysWr"><li class="social-channel-list__StyledSocialChannel-z1p8fq-1 htFYTF"><a href="https://github.com/winuss" target="_blank" rel="noopener" aria-label="github"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li></ul></section></div></div></section></main><footer class="style__StyledFooter-sc-1xdlo4d-0 hdhrBK"><div class="common__Container-sc-1wbwqlx-0 style__FooterContainer-sc-1xdlo4d-1 kcCrhV"><nav class="style__StyledNav-sc-1xdlo4d-4 cKJeHJ"><ul><li><a href="/rss.xml" rel="noopener noreferrer" class="style__FooterMenuItem-sc-1xdlo4d-5 evGsdC">RSS</a></li><li><a href="/sitemap.xml" rel="noopener noreferrer" class="style__FooterMenuItem-sc-1xdlo4d-5 evGsdC">Sitemap</a></li></ul></nav><div><p class="style__Copyright-sc-1xdlo4d-2 dkniVZ"><strong>DevTimes</strong> © <!-- -->2021</p><p class="style__DesignBy-sc-1xdlo4d-3 eysmNL">Theme by <a href="https://nehalist.io" target="_blank" rel="noopener">nehalist.io</a></p></div></div></footer></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script>
  
  
  if(true) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-168375315-1', 'auto', {});
      
      
      
      
      
      }</script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/nlp-korea-movie-review";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-a8b2574222d925c54afd.js"],"component---src-pages-404-tsx":["/component---src-pages-404-tsx-057dc180d56b15804385.js"],"component---src-pages-archive-tsx":["/component---src-pages-archive-tsx-fdf2cd80a3f85b7fc325.js"],"component---src-pages-tags-tsx":["/component---src-pages-tags-tsx-958d9cb016ae8b948b75.js"],"component---src-templates-page-tsx":["/component---src-templates-page-tsx-7ec48fbcec09fea3ec81.js"],"component---src-templates-post-tsx":["/component---src-templates-post-tsx-8a7ad919cf47b755089e.js"],"component---src-templates-posts-tsx":["/component---src-templates-posts-tsx-0e5d08b16e0a44a2a740.js"],"component---src-templates-tag-tsx":["/component---src-templates-tag-tsx-93f232bc138f470217e2.js"]};/*]]>*/</script><script src="/component---src-templates-post-tsx-8a7ad919cf47b755089e.js" async=""></script><script src="/6c18e55fdd71cb6af87612710cbe2c0cb61bdd56-92ca3db2def247415ce0.js" async=""></script><script src="/1bfc9850-693458f4bfc03c5b78c9.js" async=""></script><script src="/styles-85581d4dae49207538a9.js" async=""></script><script src="/app-a8b2574222d925c54afd.js" async=""></script><script src="/framework-737c3e16d462c41141c7.js" async=""></script><script src="/webpack-runtime-54fc4c4fe4b49e1e33de.js" async=""></script></body></html>