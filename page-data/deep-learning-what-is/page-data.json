{"componentChunkName":"component---src-templates-post-tsx","path":"/deep-learning-what-is","result":{"data":{"post":{"headings":[{"depth":1},{"depth":1},{"depth":1}],"frontmatter":{"title":"딥러닝 - 딥러닝의 이해","path":"/deep-learning-what-is","tags":["ML-DL","DeepLearning"],"excerpt":"딥러닝이라는 용어는 2006년 캐나다 토론토 대학교의 제프리 힌튼(Geoffrey Hinton) 교수의 논문을 통해 처음 사용이 되었다. 하지만 딥러닝은 사실 새로운 개념이 아니다.","created":"2019-05-16T00:00:00.000Z","createdPretty":"16 May, 2019","updated":"2019-05-16T00:00:00.000Z","updatedPretty":"16 May, 2019","featuredImage":null},"html":"<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 626px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/e085339404dde0b42eb78e5dda7480ee/af590/deep_main.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAAsSAAALEgHS3X78AAAB6UlEQVQY02NgYJZiYJFn4FBhEtHjUDLl07a0KKr337jXbPZKp5krnJonuE9eZJo3WX/SZv2JyxWTynn1vViE9RmE9GRUbBkYWKQZWBUYuNR5hXWUpI04lUzNvELdFq7xOHi8/PDRlI4ZJSu3p64+4nn4hs3SLbp13XJhmQoGzkxSxjJqDkDNMgysigw86rwS+m7mzpJ6ziomrmFTZwfduRU0b4lDeVfa5gMNF59G3H7lum6nWdtkjdgiM1NPBgEtGTVHkGZGNiUGPk1dWaPVvh72xh6GOs5+SeXeOy/5r9pklddi0LWq/O6HnGefLaas0MyqsXeMKPAKlJLSF1cF28zErsTAo+Uia7TdxMxW1dHOyNs7tsGo50LCkWvOk1dod632PXDPa/9tncxO/7TS5MicLCdfEQl9SRWwZkZ2ZQYeTRExg3wLR0dtN2fbUIu4dssF57J3nSo7eTv5+gObFUc1GlcZBuZ4xhSEZ1U4ajnwCupIq9iBAwxksyY7v26wR7CXmZ+uWZCodaTDzlMZh87n77/hcvKZWt1i+aAi/dgSba8UN4cQLSVzVj5tKWVQaEsxsIFCm4lfl0/anEXWRkDXm1PVVTGzy2/1IYc5pwWLN3HYZQk5Rcv5pokY+0loufII6zGKg0IbAHf/lB6LdLbtAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"deep-1\"\n        title=\"deep-1\"\n        src=\"/static/e085339404dde0b42eb78e5dda7480ee/af590/deep_main.png\"\n        srcset=\"/static/e085339404dde0b42eb78e5dda7480ee/5a46d/deep_main.png 300w,\n/static/e085339404dde0b42eb78e5dda7480ee/0a47e/deep_main.png 600w,\n/static/e085339404dde0b42eb78e5dda7480ee/af590/deep_main.png 626w\"\n        sizes=\"(max-width: 626px) 100vw, 626px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h1 id=\"개념\" style=\"position:relative;\"><a href=\"#%EA%B0%9C%EB%85%90\" aria-label=\"개념 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>개념</h1>\n<p><code class=\"language-text\">심층 신경망을 이용한 머신러닝 기법</code></p>\n<p>딥러닝이라는 용어는 2006년 캐나다 토론토 대학교의 제프리 힌튼(Geoffrey Hinton) 교수의 논문을 통해 처음 사용이 되었다. 하지만 딥러닝은 사실 새로운 개념이 아니다. 오래전부터 있어오던 인공신경망(Artificial Neural Network, ANN)과 크게 다를 바 없다. '인공신경망'이라고 하면 복잡한 뇌 구조를 생각하면서 어렵게 생각이 들겠지만 실제 뉴런의 행동을 살펴보면 어떻게 이렇게 단순한 행동으로 이루어질까 싶을 정도로 심플하다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 719px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/997581a633246e4c2be373eea25075e1/073e9/neuron.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsSAAALEgHS3X78AAABbUlEQVQoz11RO0/DMBDOT2dm4ifARmcWBgZWQEUVKJGaNmleVHGdNIkfsePYKee6VC3fcDrf3XePz97hGmY6TJO1o57OwWmyftd1qETOd/BcDhJHxyRY+IWQylTd0A9GSrGzwEoprXUcx1LKKzIAcmD7vieMQ+sYDTUdudQQZIxB3C1FmOilIqQzxliyEGIYBkKpWwwSSk9fxTCbyyivwihfrhNCOWyljWn4CFmjR2BRQr26qqE3PAghWVYgXOd7dfuU38yWd8/bbz9c+Ou3z+D9YzEPUYollyMhFIoxxh7nHCYzymCyUAZ1KkPk4WV9/1o8flDeS9q1ULrZJFGx36CeS8UYhcvhlpNglFInY9n06c8u27Fwy5mwQlS4aprm7y8s1KBcsSXD9dDbCYbKsmmt8kFOwi2RSp9/yzjqkeac02TY3GnuZPyHy7+9hHdRYk1RFKtwlaZpHMWBH2zg1iQBRWFz2A5s27bOwqRfrf87HrfzQKoAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"deep-1\"\n        title=\"deep-1\"\n        src=\"/static/997581a633246e4c2be373eea25075e1/073e9/neuron.png\"\n        srcset=\"/static/997581a633246e4c2be373eea25075e1/5a46d/neuron.png 300w,\n/static/997581a633246e4c2be373eea25075e1/0a47e/neuron.png 600w,\n/static/997581a633246e4c2be373eea25075e1/073e9/neuron.png 719w\"\n        sizes=\"(max-width: 719px) 100vw, 719px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span> </p>\n<p>입력신호가 오면 길이에 따른 가중치(weight)를 부여하고 임계값(bias)을 더한 후 축색돌기를 통해 이동한다. 그리고 그 값이 조건에 만족한다면 다음 뉴런으로 넘어가고 그렇지 않다면 넘어가지 않게 된다. 이러한 실제 뉴런에서 이뤄지는 과정을 그대로 수학적으로 구현한 것이다.</p>\n<p>컴퓨터가 사진 속에서 고양이를 검출해내야 한다고 생각해보자. '고양이'라는 추상적 이미지는 아마 선, 면, 형상, 색깔, 크기 등 다양한 요소들이 조합된 결과물일 것이다. 이것은 아마 '선 30cm 이상은 고양이, 이하는 고양이 아님', 또는 '갈색은 고양이, 빨간색은 고양이 아님' 처럼 간단한 선형 구분으로는 식별해 낼 수 없는 문제이다. 딥러닝은 이 과제를 선 긋고 왜곡하고 합하고를 반복하며 복잡한 공간 속에서의 최적의 구분선을 만들어 내는 목적을 가지고 있다. </p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 912px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/7623aed6067028d2d5e43fd2554ebcc7/8b69f/deep_01.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 44.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABcRAAAXEQHKJvM/AAACZUlEQVQozx1S2W7aUBD1p/QheWj7KX3qB/Sp6i/0P6pKUfISpWmzQBY1LIZgzGqMQ4wNIWAMNnsIITU4gI0prk8vudJIc+bOnDlz51LV1iMu8wqY+wau75qIlhvEVMQqDS9S1hAtNC1nbr6lyNEHw+RVXnIuudvnX3TJ8LM1w5+TDT6dN/phxpjyokHJrT6+Myp+Flo4uWvhSNJe7aSke3uZLk7zqvV3+vB+QygrDflUVnHAt3AgtHB8r6HA32EWyWDuC+KRToCS9S4OhSr2kzp8UgM+UYVfruNHVvMOeR2BUs221tjeEEo1tXgmNbHPD9a+Uttr5Eremsl5y+us5wQYr0snPKqs97BfIIRiB7tcB8cVjWAde9mOd1Rp41ysmyN65wO+UG8kZSTsJvsk1naHGRFujIPN5kEI4Vwx6NNJUL2qispFFPWsCClWAhcqQwjKUDKy1yaJCiv2hzufgi9ft07y+jMTFeow07fumpAt4zychIBlkIVDp/B0nQE1UXXMLqNwzkJYxbKYh9KwohlsRlhfRPAnVZi2Q98+Lj5T281mOz9lebgJwbVZQkTMSd5gRdTNQgmY8RyoUUXBOJyESYLmVQybgkkkBfM87M2Iisc4Zz8BW5s37IuSZAfjWEYzrkVqbKJqQcSYpLFJ/H+cBMpQmpgG4rCYHGxysfjNYHEWhkWnPCeWwzjOWQ+T8euWu5VqcewPkWa0a5CtvvhJXoAlk/EAewNsCEdaC50Uj172BgOugD6TwiBNMFfwhgR3BNGaWIt3G8Jxb1C0FR3zct11qhpWNR1rglfVJlbkHzvE/w+IqELYkMaL6wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"deep-1\"\n        title=\"deep-1\"\n        src=\"/static/7623aed6067028d2d5e43fd2554ebcc7/8b69f/deep_01.png\"\n        srcset=\"/static/7623aed6067028d2d5e43fd2554ebcc7/5a46d/deep_01.png 300w,\n/static/7623aed6067028d2d5e43fd2554ebcc7/0a47e/deep_01.png 600w,\n/static/7623aed6067028d2d5e43fd2554ebcc7/8b69f/deep_01.png 912w\"\n        sizes=\"(max-width: 912px) 100vw, 912px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>파란선과 빨간선의 영역을 구분한다고 생각해보자. 그냥 구분 선을 긋는다면 아마 왼쪽처럼 불완전하게 그을 수 있을 것이다. 하지만 공간을 왜곡하면 오른쪽 같이 아름답게 구분선을 그릴 수 있다. 이처럼 인공신경망은 선 긋고, 구기고, 합하고를 반복하여 데이터를 처리한다.</p>\n<p>그럼 어떠한 규칙으로 선을 긋고 공간을 왜곡할까? 바로 데이터에 근거하는 것이다. 일단 대충 선을 긋고 그것들을 살살 움직여가며 구분 결과가 더 좋게 나오도록 선을 움직이는 것인데 이러한 과정을 최적화(optimization)이라고 한다. 딥러닝은 아주 많은 데이터와 아주 오랜 시간의 최적화를 통해 데이터를 학습하게 된다. (양에는 장사 없다고나 할까...)</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1146px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/08a8629a5f7acb06a467b2a7501f0b22/fe9e8/deep_layer.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 55.00000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABcRAAAXEQHKJvM/AAAC0ElEQVQozzWSS0wTURSGB2wTxQe+a0piSIxo2HQBO6MLI0uJgSUi6xIXmriThRsXaEzbaKIsMJEWRMVQqaVYVDBioUhLcWyHls6003b6mEeZYmtbHj3eO62T3Jz7/3Pmy3/PHaK9rf00QRDH0dJcaLl4sL9ff6S1tbUF6UMqlUrb29uL3xN9fX0anU53Hm0Po6Xt7u7W6vV6dVNT01mkGxsaGrQ9PT0aYnHJpUvFJSMXEwbnv389hz8mSfImG2GGAgH/XSTrgsFgPfZ9Pl8X8p8H16l7BqPpKPb8fv8tlmWHKIrSNzc3q4lyDrpCWw7wxW1Q4uEybtqU5XFAT1bO/cYabVW4SpL0DPvyn3zI+fHDiZo3qfRmsy6siXy2ct3HzsAiNZ1nmW0FmOK4YdiYgwzt/4H12uKCGlculX4E1CyINLk8TYkKUBRFMwYisEMBFiToXEvYYGnDViID5WvYo2nGDM4nwKzM/0TxiBcW+wHsh1nOtOsYhPjK51WrCMpsJVEcVRJKkrMKzCJg3I4SThUDwXIH9thE0gKcB9KR4DJxCeofTvxqxH4syRuBdYMYXfeOuNgzeL7JjDCWR8C0IFSBeZSQTM6Ah3YUA1QJJ6wLb4TNMPUAIu7ZZZxwYHjumJI8mjDsTg5Awu3wTuTgFPZWGe6NmU7BGs1UgX83odPDTsKCf6LI0JWryqwy4hg+hsDzbqyNzgj+VYg0LxoAdiErCt7X9nkN9gSx2sv/Tyhm5E5ejkI8Ey56SU4BhoKhV3vjdyDicihAy8uR/bgGmbhxZ/Q2JFxTHmupmhBdiqV2KZ8U4N4W3PgWeQo2r6mSS8IV7KEEZqhsQSbBerCORxh1LY0ByhIIXIz84vadrAHf1oBzCjCVTHfwQjqV4VOhWJRtwx7PC49zheK2IEpWrMvbO/uUI6fT93OFUkHalO3W9++OVnt5kyzLRUEQLFj/A7/B9AqN+rarAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"deep-1\"\n        title=\"deep-1\"\n        src=\"/static/08a8629a5f7acb06a467b2a7501f0b22/fe9e8/deep_layer.png\"\n        srcset=\"/static/08a8629a5f7acb06a467b2a7501f0b22/5a46d/deep_layer.png 300w,\n/static/08a8629a5f7acb06a467b2a7501f0b22/0a47e/deep_layer.png 600w,\n/static/08a8629a5f7acb06a467b2a7501f0b22/fe9e8/deep_layer.png 1146w\"\n        sizes=\"(max-width: 1146px) 100vw, 1146px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n딥러닝은 하나의 뉴런이 아닌 수천 수억개의 뉴런들이 연결되어 이뤄진다. 즉 인공 신경 또한 수많은 연결들을 통해 망을 이룬다. 크게 입력층(input layer)과 출력층(output layer) 그리고 그 사이에 있는 layer들을 묶어서 은닉층(hidden layer)이라고 한다. 위 그림에서는 모든 노드가 연결되어있지만, 꼭 다 연결되어있어야 하는 것은 아니다. 단지 내가 어떻게 신경망을 구성하냐에 따라 정해지는 것이다.</p>\n<p>저렇게 망이 이뤄져 있는 것은 알겠는데, 대체 어떻게 학습을 한다는건지 이해가 안 될 수 있다.\n내가 고양이 사진을 입력에 넣었다면 출력에는 고양이라는 결과가 나와야 맞는 것이다. 고양이가 맞다면 그냥 넘어가면 되지만, 고양이가 아니라고 결과가 나왔다면 이것은 문제가 있는 것이다. 따라서 다시 뒤로 돌아가면서 각 인공 신경의 가중치(weight)와 임계값(bias) 값을 수정하게 된다. 이러한 과정을 반복하며 weight와 bias 값을 조정하고 고양이라는 결과가 나오도록 '학습' 하는 것이다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 330px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c2452f897e382afb7b6bf096ee9f9035/d9ecf/image_net.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 128.33333333333331%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAaCAYAAAC3g3x9AAAACXBIWXMAABM5AAATOQGPwlYBAAAD2klEQVRIx5WVW3PbNhCF9f//Rx/S5KEdZ+qxHXs6TT3T1KkvEi3RN8myZYmSSAIgeKeE0wNIcSI74ziaWYMEwPW3ZxfYljHmFoDiGDdNI55aXdeC62K5XIi6qd1clmfie3uXy6Vo0ZHC+leUBfIifxzpAELGePfuLfb3P2Brawtvfn2Dwd09muXice+X/fSFFv3Ea39LThprJHBjkihzeHho9vb2zPb2ttk/ODDv32+Znd09cz8aGToyaZZyf+q+aRaNaWmthdfpQCplVJoiFjGkFFCJcs83/StcXV9i0O+jP+hj9DBCr9fFbD5HmmlonSJNMyRagWGjVZalCKZTlEVhbmcSJ3Te8dpotzu4vOpDphN0rjvwBwO+X8LreAhmc+SVRp6VGMsrTOQNiryiwxot/hG+70OnDDPPLKmjk0qCISOhNvLShzw9RqxizOIJlNI4nx5AaYnr+b+0IzqvUdcVWjYzURRT1MLqxjBSUA9kHFNuyIa3mP/5G8LDPxCfHcKTf6MkTWe6C5XGGMYd3MUe5xqXxBa9Cs/rOELrKNEJnxNHl1UFNHWL/tpC/M8OwpOP8NVHZDqHF3xApAJSzzhOnZbO4WKxEPN5iLKsHKEmWcLk2PBHIZ2SMuj6CI6OMdcxdvwTFEWBSAeMInNjrGeMKl8lxTq8uPCpmzZlmSOIJE6HEUWmTqMYRZagPUnweUwpSO7dz5hV7TKrOdrs2qisOUIWo9AkKsrSVCzQIE5wNIiwqHLsdmdO095DjOPbEMs6ZzVkbu6rZWtLV4Q2y91ulxnTzHK+1lBTZI3fzwK+a7TvIny6maMpU8hktf7U7HfrkBsRRpHTsLIhk/DzbYS6yhypotgi0QhZKlbXTbpNWxM2onvuOQ0LJiWUCoOpcBp69zGESii+dmZpv0e3QWjrUErpCG1S5jLB+YNAXWb41I8cHc/qi2QbhDZkqyFJTMO6uwlivP1v7DTMszWB/oE9JVQMq6pWhCEJ/bFweunsdWTPCM95UiyhTcqEdXjCOlxpljwS/Mi+1iEJU9ZhWdWmqRnyVOKXo7HT8NWEebpZh+12mzezchoOZ4IFPWWW0xez+mKWLSF7h7u+Ei5K/XPaWbNOnUMbcs/v8XaWxh56+5/S9PVkzwjtWa6q2r646+tnM/uM0Dap4XDIHhEtSzYdZtVwcWXfPn8zl66fKdXGmoWyDpX1XNPsbzwe4/T0FCGb0NnZGVtBAlv41zd9TMYP8M57CMMINpH2HvW55l9cfunELmTb6BPbzK3ZZk4tXeO2DcwmzY4sfNGw6fOIcm2xsceusSW77/8HgyG2igORzRcAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"deep-1\"\n        title=\"deep-1\"\n        src=\"/static/c2452f897e382afb7b6bf096ee9f9035/d9ecf/image_net.png\"\n        srcset=\"/static/c2452f897e382afb7b6bf096ee9f9035/5a46d/image_net.png 300w,\n/static/c2452f897e382afb7b6bf096ee9f9035/d9ecf/image_net.png 330w\"\n        sizes=\"(max-width: 330px) 100vw, 330px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>2012년 이미지넷에서 이미지 분류 대회가 있었다. 1000개의 카테고리와 100만개의 이미지로 구성되어 분류 정확도를 겨루는 대회이고, 아래 사진만 보더라도 딥러닝이 이미지 인식 부문에서 얼마나 큰 영향을 끼치고 있는지 알 수 있다. 이 대회 이전에는 기계의 이미지 인식률이 75%를 넘지 못했고 80% 이상의 인식률은 불가능이라는 인식이 있었다. 하지만 이 대회에서 힌튼 교수의 제자 알렉스가 알렉스넷(AlexNet)이라는 딥러닝 기반 알고리즘으로 84.7%를 찍었고, 이후로는 대부분의 참가자들이 딥러닝으로 방향을 돌렸다. 현재는 오류율이 5% 이하의 정확도로 인간의 인식수준을 뛰어넘었다.</p>\n<p>딥러닝이 대단한 것은 일반적인 기계 학습과 달리 특징 추출(feature extraction)이 자동적으로 이루어지는 점 이다. 기존에는 효과적인 특징을 추출하기 위해 관련 분야 전문가가 오랜 시간동안 직접 특징을 추출하는 수식이나 방법을 고안해야 했다. 이 방법은 개발, 평가 및 보완에 많은 시간이 걸리는데 딥러닝은 이런 과정을 컴퓨터가 대신 하도록 알고리즘을 짠 것으로, 사람에 비해 훨씬 빠르고 효과적으로 수행해도록 학습시켜준다.</p>\n<h1 id=\"발전과정\" style=\"position:relative;\"><a href=\"#%EB%B0%9C%EC%A0%84%EA%B3%BC%EC%A0%95\" aria-label=\"발전과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>발전과정</h1>\n<p>딥러닝의 발전과정을 보면 아주 오래전부터 시작이 되었고 지금에 이르기까지 많은 이들의 노력이 있었다.</p>\n<p><code class=\"language-text\">1957 : 최초 신경망 모델 Perceptron 등장</code></p>\n<p>퍼셉트론은 인간의 두뇌 움직임을 수학적으로 구성하였다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 773px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/e45527b7992b2fa15a56b8b815684ebe/612f7/deep_02.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAABXUlEQVQoz32SfW+CQAzG+f4facmcZo5o1Pj2H6AI5xsIJ2+iiPqsrdMty7JLfint9crT3hmbzQZRFKEoCpzPZxyPR1RVhbqucTgccDqdxC/L8mk5h+OP/UeM943RaITJZILhcIhev4f+YEC2j263A9M0yXYxnU7RbDYxHo8xn81gWRbm8zks24Lv+/A8D0op6P0eRhAEmFHSdruFS0mu7SCgb07gWBiGCHe7uyV+r9vthjRNkWWZYLBMJqeWj8Qp1pz184gceqzr9SpwjLlcLiLIdV0RYXBSnufkLLEhRWuClfFsmdVqJcriOJbD3JFt21KA22XW6zUcx5EfSEFWqHWMvdZ39prm8W3vQy/pos5yEUmSSpssJEkSaZV9Vi4FizxDr9PGx3tDUGoBtfSxJJTySMXdL4qMVNb4b321nMJsv6HdekWr8YKFO8NyxZfCLSspzGgd0dOqnvP7i09IslrDMjep8QAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"deep-1\"\n        title=\"deep-1\"\n        src=\"/static/e45527b7992b2fa15a56b8b815684ebe/612f7/deep_02.png\"\n        srcset=\"/static/e45527b7992b2fa15a56b8b815684ebe/5a46d/deep_02.png 300w,\n/static/e45527b7992b2fa15a56b8b815684ebe/0a47e/deep_02.png 600w,\n/static/e45527b7992b2fa15a56b8b815684ebe/612f7/deep_02.png 773w\"\n        sizes=\"(max-width: 773px) 100vw, 773px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p><code class=\"language-text\">1957 ~ 1986 : 첫 빙하기(30년)</code></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 732px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9dd8ee15286984a24ff73ccc93e0244e/d0cc0/deep_03.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAABYUlEQVQoz1VS23KCQAzlq6WfUR/UUV/8MkVtBTvDRXa57AVOkyy0mJklm3OSbEgSgWQYBqhawXmPYRwZwjhpYy3xo+Ce/N44YwUfJ5wl4o93Hq1SeKkGuu3fgvLyhbY3Emisw1wAi247GIolAM/sB7XSiDjQU2WWKqEs0ASyPUtHQVy9dU4e4cMJWRt6aK4uLyooTijVENhQkCTueizFUpChpFWt0fX2rcKu6eCMQUe/bn3AIq01yqpCnudyKrrXdR1+ibiiKFCUJUrSJWlFreHqWLPNMcxVVeCi0+mEOP7AZrPB4XCU+3a7lYSBi/G5Xsthbr/fC3c8/vvudjusVrH4R9nzifP5gvv9C8n1hsslwffjIUFpmol9u90Dl1yJS4VjnZDNOPNn8kuzLPTQTUPw1Afu47BYD8bmQSz7xys0D2d5Ik5gqLE85Z4HMN3lIZos7yHbAXd/3Hyf/XknGfsF5Mum8uXhc5cAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"deep-1\"\n        title=\"deep-1\"\n        src=\"/static/9dd8ee15286984a24ff73ccc93e0244e/d0cc0/deep_03.png\"\n        srcset=\"/static/9dd8ee15286984a24ff73ccc93e0244e/5a46d/deep_03.png 300w,\n/static/9dd8ee15286984a24ff73ccc93e0244e/0a47e/deep_03.png 600w,\n/static/9dd8ee15286984a24ff73ccc93e0244e/d0cc0/deep_03.png 732w\"\n        sizes=\"(max-width: 732px) 100vw, 732px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>그 당시 AND와 OR의 경우 퍼셉트론을 통한 선형 분리(linearly separable)가 가능했다. 따라서 AND / OR 연산이 가능하게 훈련한 퍼셉트론을 보고 많은 사람들은 기계의 학습 가능성에 대해 큰 기대를 하게 되었다.\n하지만 이러한 그들의 엄청난 기대에 찬물을 끼얹어버린 것이 XOR 연산에 대한 불가능이었다. 당시 하나의 인공 신경. 즉 퍼셉트론으로는 선형 분리가 불가능해 XOR 연산에 대한 학습이 불가능했다. </p>\n<p>1969년 이 문제를 해결하기 위해 퍼셉트론을 다중으로 겹치면 이 문제를 해결할 수 있음을 증명한 <strong>다중 계층 퍼셉트론이 등장</strong>하지만 레이어가 복잡해질수록 연산이 복잡해져서 현실적으로 파라미터값을 구하는 것이 불가능 하였다.</p>\n<p><code class=\"language-text\">1986 : 새로운 학습 방법 등장</code></p>\n<p>데이터가 모델을 스스로 찾아내는 역전파(Backpropagation) 등장\n즉 앞의 진행방향에서 고쳐가는 것이 아니라 결과를 보고 뒤로 가면서 weight와 bias를 조정하는 방법을 고안 하였고, XOR 뿐 아니라 좀 더 복잡한 과정도 해결할 수 있음을 보이며 다시 인공 신경망은 사람들의 관심을 끌기 시작했다.</p>\n<p><code class=\"language-text\">1990 : BOOM</code></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 703px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ead2eaf3f6e6c95306ad4b1bb2122895/242e2/deep_04.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAACkElEQVQoz62TzU4TURiGZ1pK6QClnXb6M/0dOpRCKS1VOq20aFsqExFi+QsJRMUF4g8RFyYuXGA0rkx0ZeLGxCswMWpcuPcOXLv2Jh5PRxNvwMWXN3Py5Zn3fO93JEmS+K+lqGl8gQSSW3y4JEdlj0QyYTBXvIAS1BhRw/iCYUe9/jHkYRey14M0NOiXcSs+3L4RlLEQUqTQIzRZc5oc6PCfalxY5/joJenSEoGpOUL5ObRCmaRpYuZNitUGAT2GrHjxhqN4QyHC+jRSvLhGPGEyNACJP7p9MkFNpdrY4PD4Fbnza0zkLdSZJfRSE3O6wKVWl4sruxQa11BSBRTdxKNqjGsZ4TDfJKuncAnYiCLh8UksCph95Zj5aht9YZX4oCo2iarN3HyZxVqLc1aPxct3KFibRHILDEczjA8cZko9Lrb2mcnNEtEmxBxk7PW7NDvXSaUMUgtrREVPvCxGU+xSsVbor26y3N6mvfWYfGOPSLEnnM4yblhItZ13dOyHIoQsMXF1v+onN13Fsvp0+2cs3/tA+/QjvUdfuXL2jd3X3zk4OqNl38TaOCVr7ZG29hnNVBgzmkjF1glmue8EMjzqcTSSnKTTvUFz9y3dJz+wn/3EfvGL25/h8AusnbzBXt1m1tpgLC4Cm7mKP7dEdGEHaURAvON+YnoCVQsT0eNkpiqs7D6nfusTRu8p0eoB+vJj6vffk2xsocVi1GtNgiFVhCECDc3ijZZJt58i+QMhx1VMz1CYqVOr95m3tplsHFJY2idX6ZApddDNEmEx40DQ929nZRGkNiVgFdyjKoHyA3Emu8WGy86Wu1xuRycm/EwaWZLJBNFojEzWIJ1OC81imnkMw0BRlH+vY8D4y/kNpT49psy38/gAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"deep-1\"\n        title=\"deep-1\"\n        src=\"/static/ead2eaf3f6e6c95306ad4b1bb2122895/242e2/deep_04.png\"\n        srcset=\"/static/ead2eaf3f6e6c95306ad4b1bb2122895/5a46d/deep_04.png 300w,\n/static/ead2eaf3f6e6c95306ad4b1bb2122895/0a47e/deep_04.png 600w,\n/static/ead2eaf3f6e6c95306ad4b1bb2122895/242e2/deep_04.png 703w\"\n        sizes=\"(max-width: 703px) 100vw, 703px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>{: width=\"400px\" }\n(터미네이터2 심판의 날 (1991) 대사 中)</p>\n<p>영화 중반부에 터미네이터인 아놀드의 대사 중에 \"My CPU is a neural-net processor.\" 라는 말이 나온다. 스스로 학습할 수 있는 기계를 neural-net processor 라는 말로 설명했고 이 당시에도 neural network에 관심이 있었음을 알 수 있다. </p>\n<p><code class=\"language-text\">1990 ~ 2000 : 두번째 빙하기(10년)</code>\n신경망이 깊어질수록 원하는 결과를 얻을 수 없다. 오히려 성능이 저하되는 경우가 발생.</p>\n<p>다음의 문제를 해결하는데 10년이 걸리게 된다.</p>\n<ol>\n<li>Overfitting (과하거나)</li>\n<li>Vanishing Gradient (덜하거나)</li>\n<li>Too slow  (느리거나)</li>\n</ol>\n<p>이런 문제를 해결하기 위해 연구하는 10년 동안 GUP를 활용한 연산시도, 알고리즘의 발전이 있게 된다.(SVM, Random Forest 등장)</p>\n<p><code class=\"language-text\">2000 : 3가지 한계점의 해결방안 등장</code></p>\n<ol>\n<li>\n<p>과한 적합 해결</p>\n<ul>\n<li>Droupout</li>\n</ul>\n</li>\n<li>\n<p>덜한 적합 해결</p>\n<ul>\n<li>ReLU(Rectified Linear Unit) : 수렴속도가 시그모이드류 함수 대비 6배 빠름</li>\n</ul>\n</li>\n<li>\n<p>느린 적합 해결</p>\n<ul>\n<li>Adam : 확룰적 경사 하강법(SGD)에서 더 나아가 학습속도와 운동량을 고려한 옵티마이저가 등장</li>\n</ul>\n</li>\n</ol>\n<p><code class=\"language-text\">2006 : 드디어 Deep Network. Deep Learning 용어가 사용되기 시작</code></p>\n<p>이러한 여러번의 실패로 인해 이후 나온 논문에서는 neural net이라는 단어를 찾을 수 없었고 neural 대신 deep 이라는 단어를 사용했다. 이 당시 neural network 라는 말만 들어가면 논문에서 거절당한다는 말이 있을 정도로 신경망이 외면받던 시기였기 때문에 좀 더 사람들의 이목을 끌 수 있는 단어를 택했던 것 같다.</p>\n<h1 id=\"마치며\" style=\"position:relative;\"><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\" aria-label=\"마치며 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>마치며</h1>\n<p>딥 러닝이 화두가 되고 있는 것은 비교적 최근의 일이지만, 딥 러닝의 기본 구조인 인공 신경망(Artificial Neural Network)의 역사는 오래되었다. 1957년에 등장한 초기 신경망인 퍼셉트론(Perceptron)으로 시작해 최근에 쓰이고 있는 발전된 신경망 RNN, LSTM에 대해서도 좀더 자세히 알아보면 좋을 것 같다.</p>"},"primaryTag":{"name":"ML-DL","color":"#4bc822"}},"pageContext":{"postId":"a6a76604-8ef6-5b84-b3d8-b7df59efa99d","primaryTag":"ML-DL"}}}