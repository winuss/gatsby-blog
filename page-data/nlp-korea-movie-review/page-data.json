{"componentChunkName":"component---src-templates-post-tsx","path":"/nlp-korea-movie-review","result":{"data":{"post":{"headings":[{"depth":3},{"depth":3},{"depth":3},{"depth":3},{"depth":3},{"depth":3}],"frontmatter":{"title":"NLP - 한국어 영화 리뷰 감정분석","path":"/nlp-korea-movie-review","tags":["ML-DL","ML","NLP"],"excerpt":"네이버 영화 리뷰 데이터를 이용한 긍정/부정 예측하기","created":"2020-05-24T00:00:00.000Z","createdPretty":"24 May, 2020","updated":"2020-05-24T00:00:00.000Z","updatedPretty":"24 May, 2020","featuredImage":{"childImageSharp":{"sizes":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsSAAALEgHS3X78AAACYklEQVQozx2SS2sTYRSG51e4sGrTGE2azH3mm8kkk2SSSZM0qUlMdFG1otQLQsWqINVWrKLipYILETdiwYV4QbEgeMGNVEF3KuIPEPwB/oHHT9cHzvO857xKoGZIZzL4tkWobqespmjU6gwHfTrtJp1Ok7znIGwD4bro2TTq2Aix16ZXnWZQ72Ftt/FMjaBQRhn0pxj0OnhyYeTb6H4R4XuUwwDhmISlIq5joaa3YgpBUndZmp/j/fOPrN56zNLsJTrOkJqWI7dpA0oc+lTzNnHRo+pb1Es+7WZMa7JBPFGVtiEVoTFRMMmb49R8g/VXL/jz6wfP7r3k7MwNFncd5dzOPrFMqMTjW2RcjWajSsGzKLoGQV7gmCpF38XLpcglN+E5Bo40bkvQg2vXubOwwOvVp5zsTtExLXaLIvOTRZTd3QaTgUE3n6Me2DQaMaVykTgUtGoFKtLI1jMEngQJnR2dFiuLF7h44hSr5xbY46UJsgbznZCVvRGKYf8jG2TTKRxLkya6NHOIKjJqKfhvpWbkTJpq6QT9iYjf37/xY32dyweGnO22WJ7ez8q+LrdneihRwcOd7CFqMfWoTGQ75NQcgbyXsHW2JJOY2RSWmsbOJvDlp39++syXtSfcnRtyrH6coT7LmVjl2s4WilsqkXF90qbNVs1ksxGS8CPccoUxN0QrVNBEntGszjZVRUQTvHn0jqe373N++iD7giFHwgpX+hYLcQll1PAoRBWmBl1Eo82oX/sPMGWvMokRtLGNGCn5lFwCT03KaqmsPXzLh7WvLB++ymK/yemG4ObQ51A74i/iik3FpHalwgAAAABJRU5ErkJggg==","aspectRatio":2.2988505747126435,"src":"/static/3081b292a1f8afbb61de9dd1ab205863/c0491/cover.png","srcSet":"/static/3081b292a1f8afbb61de9dd1ab205863/dc47e/cover.png 200w,\n/static/3081b292a1f8afbb61de9dd1ab205863/9f2d5/cover.png 400w,\n/static/3081b292a1f8afbb61de9dd1ab205863/c0491/cover.png 460w","sizes":"(max-width: 460px) 100vw, 460px"}}}},"html":"<p>한국어 데이터에 대해서 텍스트 분석을 해보자. 아래 데이터는 한국어 분석 학습을 위해 다양한 방식으로 사용되고 있다. 여기서는 한글 분석을 위해 Konlpy를 사용하고, 텐서플로 케라스를 이용해 모델을 만들도록 하겠다.</p>\n<p><strong>데이터셋 : Naver sentiment movie corpus</strong>\n(다운로드 링크 : <a href=\"https://github.com/e9t/nsmc/\">https://github.com/e9t/nsmc/</a>)</p>\n<p>NSMC 약어까지 사용할 정도로 많이들 사용하는 데이터 인듯 싶다.</p>\n<p><strong>데이터 설명</strong></p>\n<p>영화 리뷰 중 영화당 100개의 리뷰이고 총 200,000개의 리뷰(train:15만, test:5만)</p>\n<p>1점 ~ 10점 까지의 평점 중에서 중립적인 평점(5점~8점)을 제외하고 분류를 하였다.</p>\n<ul>\n<li>부정 : 1점 ~ 4점</li>\n<li>긍정 : 9점 ~ 10점</li>\n</ul>\n<p>칼람정보: id, document, label</p>\n<ul>\n<li>id: 리뷰 아이디</li>\n<li>document: 리뷰 내용</li>\n<li>label: 레이블 (0: negative, 1: positive)</li>\n</ul>\n<p>각 파일에 대한 리뷰 갯수</p>\n<ul>\n<li>ratings.txt: All 20만</li>\n<li>ratings_test.txt: 5만</li>\n<li>ratings_train.txt: 15만</li>\n</ul>\n<p>모든 리뷰텍스트는 140자 이내이고, 각 감정 분류는 동일하게 샘플링 된다.(i.e., random guess yields 50% accuracy)</p>\n<ul>\n<li>10만개의 부정적인 리뷰</li>\n<li>10만개의 긍정적인 리뷰</li>\n<li>중립적인 리뷰는 제외</li>\n</ul>\n<h3 id=\"데이터-준비\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A4%80%EB%B9%84\" aria-label=\"데이터 준비 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 준비</h3>\n<p>다운로드 받은 데이터를 pandas를 이용해 읽어보자. 필드 구문이 탭으로 되어 있기 때문에 <code class=\"language-text\">\\t</code>로 구분자를 지정해주어야 한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n\ntrain_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"data_naver_movie/ratings_train.txt\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span>\ntest_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"data_naver_movie/ratings_test.txt\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"데이터-전처리\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC\" aria-label=\"데이터 전처리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 전처리</h3>\n<p>데이터를 학습 시키기 위해 전처리를 진행해야 하는데, Konlpy를 이용해 <code class=\"language-text\">형태소 분석 및 품사 태깅</code>을 하도록 하자.</p>\n<p>영어의 경우 주어진 단어의 빈도만을 사용해서 처리해도 크게 문제는 없지만 한국어는 영어와는 달리 띄어쓰기로 의미를 구분짓기에는 한계가 있고, 리뷰 특성상 맞춤법이나 띄어쓰기가 제대로 되어있지 않는 경우가 있을 수 있기 때문에 정확한 분류를 위해서는 Konlpy를 이용하는 것이 좋다.</p>\n<blockquote>\n<p>Konlpy는 띄어쓰기 알고리즘과 정규화를 이용해서 맞춤법이 틀린 문장도 어느 정도 고쳐주면서 형태소 분석과 품사를 태깅해주는 여러 클래스를 제공하고 있다.^^!</p>\n</blockquote>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> konlpy<span class=\"token punctuation\">.</span>tag <span class=\"token keyword\">import</span> Okt\nokt <span class=\"token operator\">=</span> Okt<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nokt<span class=\"token punctuation\">.</span>pos<span class=\"token punctuation\">(</span><span class=\"token string\">u'흔들리는 꽃들 속에서 네 샴푸향이 느껴진거야'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[(&#39;흔들리는&#39;, &#39;Verb&#39;),\n (&#39;꽃&#39;, &#39;Noun&#39;),\n (&#39;들&#39;, &#39;Suffix&#39;),\n (&#39;속&#39;, &#39;Noun&#39;),\n (&#39;에서&#39;, &#39;Josa&#39;),\n (&#39;네&#39;, &#39;Noun&#39;),\n (&#39;샴푸&#39;, &#39;Noun&#39;),\n (&#39;향&#39;, &#39;Noun&#39;),\n (&#39;이&#39;, &#39;Josa&#39;),\n (&#39;느껴진거야&#39;, &#39;Verb&#39;)]</code></pre></div>\n<p>테스트 삼아 간단한 문장을 넣고 확인 해보면 이런 형태로 분리를 해주는 것을 알수 있다.</p>\n<p>토크나이즈 함수를 만들어 사용하도록 한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">tokenize</span><span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">#형태소와 품사를 join</span>\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'/'</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>t<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> t <span class=\"token keyword\">in</span> okt<span class=\"token punctuation\">.</span>pos<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">,</span> norm<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> stem<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></code></pre></div>\n<blockquote>\n<p>norm은 정규화, stem은 근어로 표시하기를 나타냄</p>\n</blockquote>\n<p>리뷰가 null인 경우 위 위 함수에서 오류가 발생할 수 있으니 사전에 null값 확인해보고 빈민자열로 대체하자!</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">train_df<span class=\"token punctuation\">.</span>isnull<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">any</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#document에 null값이 있다.</span>\ntrain_df<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train_df<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">#null값을 ''값으로 대체</span>\n\ntest_df<span class=\"token punctuation\">.</span>isnull<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">any</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ntest_df<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test_df<span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">#null값을 ''값으로 대체</span></code></pre></div>\n<p>이제 학습데이터와 테스트데이터를 분석하여 저장해두자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#tokenize 과정은 시간이 오래 걸릴수 있음...</span>\ntrain_docs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>tokenize<span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> row<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> row <span class=\"token keyword\">in</span> train_df<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">]</span>\ntest_docs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>tokenize<span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> row<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> row <span class=\"token keyword\">in</span> test_df<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">]</span></code></pre></div>\n<p>분석결과가 끝났으면 다음과 같은 형태로 데이터가 변형 되었을 것이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>train_docs<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>test_docs<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">([&#39;아/Exclamation&#39;, &#39;더빙/Noun&#39;, &#39;../Punctuation&#39;, &#39;진짜/Noun&#39;, &#39;짜증나다/Adjective&#39;, &#39;목소리/Noun&#39;], 0)\n([&#39;굳다/Adjective&#39;, &#39;ㅋ/KoreanParticle&#39;], 1)</code></pre></div>\n<p>15만 학습데이터에 분리된 토큰 개수를 살펴보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">tokens <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>t <span class=\"token keyword\">for</span> d <span class=\"token keyword\">in</span> train_docs <span class=\"token keyword\">for</span> t <span class=\"token keyword\">in</span> d<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"토큰개수:\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>tokens<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">토큰개수: 2159921</code></pre></div>\n<p>이제 이데이터를 가지고 nltk를 이용해 전처리를 한다. <code class=\"language-text\">Text</code> 클래스는 문서를 편리하게 탐색할 수 있는 다양한 기능을 제공하고 있다.</p>\n<p>여기서는 <code class=\"language-text\">vocab().most_common</code> 매서드를 이용해 데이터가 가장 자주 사용되는 단어를 가져올 때 사용하겠다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> nltk\ntext <span class=\"token operator\">=</span> nltk<span class=\"token punctuation\">.</span>Text<span class=\"token punctuation\">(</span>tokens<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'NMSC'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#토큰개수</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">.</span>tokens<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#중복을 제외한 토큰개수</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">.</span>tokens<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#출력빈도가 높은 상위 토큰 10개</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">.</span>vocab<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>most_common<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">2159921\n49894\n[(&#39;./Punctuation&#39;, 67778), (&#39;영화/Noun&#39;, 50818), (&#39;하다/Verb&#39;, 41209), (&#39;이/Josa&#39;, 38540), (&#39;보다/Verb&#39;, 38538), (&#39;의/Josa&#39;, 30188), (&#39;../Punctuation&#39;, 29055), (&#39;가/Josa&#39;, 26627), (&#39;에/Josa&#39;, 26468), (&#39;을/Josa&#39;, 23118)]</code></pre></div>\n<h3 id=\"데이터-탐색\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%83%90%EC%83%89\" aria-label=\"데이터 탐색 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 탐색</h3>\n<p>출력빈도가 높은 상위 토큰 10개를 matplotlib을 이용해 그래프로 확인해보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token operator\">%</span>matplotlib inline</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">from</span> matplotlib <span class=\"token keyword\">import</span> font_manager<span class=\"token punctuation\">,</span> rc\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntext<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span><span class=\"token number\">50</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1180px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/5e6ea63c51a3bda8081412b5c6840e56/c83ae/korea_movie_review_plot.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 55.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABRElEQVQoz62Ry0rDUBCGz8Y3qKnP5AO4bqK+mN12Ebwgbow0uBRRm3vQopvSbsTYnMuckzgTm1KkBIQe+Pnn/DP5mCTs8tztFcsy5Jx/CCHe0Kebwmz6N9uiV5yblWV5w+7HnsUliHoHBwAidn11YUmlvkoJtdbaKAAD/xcQUCn1zMZ3t/sIKQSY2hhdUQ/Bjdq6KyMn6Ar4ws6GwwNjTCExWwpVmWZoPbjt4W6g67p9bBQUFFxWpVC16d6mG+j7fq8FolffCCVJBfT6tHGlNVTUozuprTcyvQaORqM+Bp+/A6BIAv/SkktV4LpcKMAS8Ds3Pd24xmvjoIkGIFfAR+Z5nlXv6Egp3xlS9xaLxVEYhid5ng+yLBukaWqn6EmS2FmaOFkSO3EcO2FEirBObKztSRAcB0FIuf3wNDmdzeeHbNfnB3BY7E9yM0ftAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/5e6ea63c51a3bda8081412b5c6840e56/c83ae/korea_movie_review_plot.png\"\n        srcset=\"/static/5e6ea63c51a3bda8081412b5c6840e56/5a46d/korea_movie_review_plot.png 300w,\n/static/5e6ea63c51a3bda8081412b5c6840e56/0a47e/korea_movie_review_plot.png 600w,\n/static/5e6ea63c51a3bda8081412b5c6840e56/c83ae/korea_movie_review_plot.png 1180w\"\n        sizes=\"(max-width: 1180px) 100vw, 1180px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>모델을 만들기 위해 백터화를 해야 하는데, 자주 사용되는 토큰 10000개를 사용해 데이터를 백터화 하자.(원 핫 인코딩 대신 CountVectorization을 사용)</p>\n<p>문서 집합에서 단어 토큰을 생성하고 각 단어의 수를 세어 BOW(Bag of Words) 인코딩한 벡터를 만드는 역할을 한다.</p>\n<p>시간이 오래 걸리므로 100개만 해보자...</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">FREQUENCY_COUNT <span class=\"token operator\">=</span> <span class=\"token number\">100</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">#시간적 여유가 있다면 10000개를 해보도록~</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">selected_words <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>f<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> f <span class=\"token keyword\">in</span> text<span class=\"token punctuation\">.</span>vocab<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>most_common<span class=\"token punctuation\">(</span>FREQUENCY_COUNT<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></code></pre></div>\n<p>이 과정은 데이터 양이 큰 만큼 시간이 오래 걸리기 때문에 이 작업을 반복하지 않도록 태깅을 마친 후에는 json파일로 저장하는 것도 좋은 방법이다.</p>\n<p>문서에서 상위로 선택된 단어들중 몇개가 포함이 되는지를 알아야 한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#단어리스트 문서에서 상위 10000개들중 포함되는 단어들이 개수</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">term_frequency</span><span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span>doc<span class=\"token punctuation\">.</span>count<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> word <span class=\"token keyword\">in</span> selected_words<span class=\"token punctuation\">]</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#문서에 들어가는 단어 개수</span>\nx_train <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>term_frequency<span class=\"token punctuation\">(</span>d<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> d<span class=\"token punctuation\">,</span>_ <span class=\"token keyword\">in</span> train_docs<span class=\"token punctuation\">]</span>\nx_test <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>term_frequency<span class=\"token punctuation\">(</span>d<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> d<span class=\"token punctuation\">,</span>_ <span class=\"token keyword\">in</span> test_docs<span class=\"token punctuation\">]</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#라벨(1 or 0)</span>\ny_train <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>c <span class=\"token keyword\">for</span> _<span class=\"token punctuation\">,</span>c <span class=\"token keyword\">in</span> train_docs<span class=\"token punctuation\">]</span>\ny_test <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>c <span class=\"token keyword\">for</span> _<span class=\"token punctuation\">,</span>c <span class=\"token keyword\">in</span> test_docs<span class=\"token punctuation\">]</span></code></pre></div>\n<p>이렇게 하면 x축 데이터에는 단어들이 빈도수 정보?, y축에는 분류 결과를 깔끔하게 정리할 수 있다.</p>\n<p>이제 데이터를 float로 형 변환 시켜주면 데이터 전처리 과정은 끝~~</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">x_train <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>asarray<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float32'</span><span class=\"token punctuation\">)</span>\nx_test <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>asarray<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float32'</span><span class=\"token punctuation\">)</span>\n\ny_train <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>asarray<span class=\"token punctuation\">(</span>y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float32'</span><span class=\"token punctuation\">)</span>\ny_test <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>asarray<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float32'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"데이터-모델링\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%AA%A8%EB%8D%B8%EB%A7%81\" aria-label=\"데이터 모델링 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 모델링</h3>\n<p>텐서플로 케라스를 이용해 모델을 만들어 보자.</p>\n<p>레이어 구성은 두개의 Danse층은 64개의 유닛을 가지고 활성함수는 relu를 사용하고, 마지막층은 sigmoid 활성화 함수를 사용해 긍정 리뷰일 확률을 출력할 것이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\n<span class=\"token comment\">#레이어 구성</span>\nmodel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">,</span> input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>FREQUENCY_COUNT<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>손실 함수는 binary_crossentropy, RMSprop 옵티마이저를 통해 경사하강법을 진행</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#학습 프로세스 설정</span>\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>RMSprop<span class=\"token punctuation\">(</span>lr<span class=\"token operator\">=</span><span class=\"token number\">0.001</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    loss<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>binary_crossentropy<span class=\"token punctuation\">,</span>\n    metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>metrics<span class=\"token punctuation\">.</span>binary_accuracy<span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">)</span></code></pre></div>\n<p>배치 사이즈는 512, 에포크는 10번으로 학습</p>\n<p>자, 이제 학습을 시켜 모델을 만들어 보자! 먼가 있어 보이는 진행률 상태를 볼 수 있다.:)</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#학습 데이터로 학습</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">512</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">WARNING:tensorflow:From C:\\Users\\DESKTOP\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/10\n150000/150000 [==============================] - 17s 115us/sample - loss: 0.5611 - binary_accuracy: 0.6948s - loss: 0.6134 - binary_accuracy:  - ETA: 21s - loss: 0.6108 - binary_accuracy: 0. - ETA: 20s -  - ETA: 15s - loss: 0.5957 - binary_accuracy: 0.67 - ETA: 15s - loss: 0.5955 - binary_accuracy: 0.67 - ETA: 15s - loss: 0.5951 - binary_accura - ETA: 14s - loss: 0.5930 - binary_accuracy: 0. - ETA: 14s - loss: 0.5923 - binary_accuracy:  - ETA: 13s - loss: 0.5911 - binary_accura - ETA: 8s - loss: 0.5785 - binary_accuracy: 0. - ETA: 8s - loss: 0.5771 - binary_accuracy: 0.68 - ETA: 8s - loss: 0.5764 - binary_accuracy:  - ETA: 7s - loss: 0.5751 - binary_accura - ETA: 6s - loss: 0.5727 - binary_accuracy: - ETA: 6s - loss: 0.5713 - binary_accuracy: 0.6 - ETA: 5s - loss: 0.5708 - binary_a - ETA: 4s - loss: 0.5685 - binary_accuracy: - ETA: 4s - loss: 0.5676 - binary_accuracy: 0.691 - ETA: 4s - loss: 0.5674 - binary_a - ETA: 2s - loss: 0.5652 - binary_accuracy: 0.692 - ETA: 2s - loss: 0.5651 - binary_accurac - ETA: 1s - loss: 0.5639 - binary_accuracy - ETA: 1s - loss: 0.5628 - binary_accuracy: 0.694 - ETA: 1s - loss: 0.5627 - binary_accuracy: 0.694 - ETA: 1s - loss: 0.5626 - binary_accuracy: 0.694 - ETA: 1s - loss: 0.5623 - binary_accuracy: 0.694 - ETA: 1s - loss: 0.5623 - binary_accuracy:  - ETA: 0s - loss: 0.5615 - binary_accuracy: 0.69 - ETA: 0s - loss: 0.5612 - binary_accuracy: 0.694 - ETA: 0s - loss: 0.5613 - binary_accuracy: 0.6\nEpoch 2/10\n150000/150000 [==============================] - 12s 83us/sample - loss: 0.5313 - binary_accuracy: 0.71254s - loss: 0.5221 - binary_ac - ETA: 15s - loss: 0.5345 - binary_accuracy:  - ETA: 16s - loss: 0.5377 - binary_accuracy - ETA: 14s - loss - ETA: 13s - lo - ETA: 7s - loss: 0.5341 - binary_accuracy: 0.71 - ETA: 7s -  - ETA: 4s - loss: 0.5340 - binary_accur - ETA: 3s - loss: 0.5335 - binary_accuracy: 0.71 - ETA: 3s - loss: 0.5335 - binary_ - ETA: 2s - loss: 0.5325 - binary_accuracy: 0 - ETA: 1s - loss: 0.\nEpoch 3/10\n150000/150000 [==============================] - 13s 86us/sample - loss: 0.5236 - binary_accuracy: 0.7170s - loss: 0.5284 - binary_accuracy - ETA: 10s - los - ETA: 9s - loss: 0.5255 - binary_accurac - ETA: 9s - loss: 0.5250 - binary_accuracy: 0. - ETA: 9s - loss: 0.5255 - binary_accuracy: 0.716 - ETA: 9s - loss: 0.5254 - binary - ETA: 8s - loss: 0.5247 - binary_acc - ETA: 7s - loss: 0.5251 - binary_accuracy: 0.7 - ETA: 7s - loss: 0.5252 - binary_accuracy: 0.71 - ETA: 7s - loss: 0.5249 - binary_accuracy: 0.716 - ETA: 7s - loss: 0.5248 - binary_accuracy: 0.7 - ETA: 6s - loss: 0.5245 - binary_accuracy: - ETA: 6s - loss: 0.5246 - binary_accuracy: 0 - ETA: 5s - loss: 0.5247 - bina - ETA: 5s - loss: 0.5249 - b - ETA: 3s - loss: 0.5246 - binary_ac - ETA: 2s - loss: 0.5246 - binary_ac - ETA: 2s - loss: 0.5244 - binary_accuracy: 0.71 - ETA: 2s - loss: 0.5244 - binary_accuracy: - ETA: 1s - loss: 0.5242 - binary_accur - ETA: 1s - loss: 0.5243 - binary_accuracy: 0 - ETA: 0s - loss: 0.5243 - binary_accuracy - ETA: 0s - loss: 0.5239 - binary_accuracy: 0.7 - ETA: 0s - loss: 0.5237 - binary_accuracy: 0.7 - ETA: 0s - loss: 0.5236 - binary_accuracy: 0.71\nEpoch 4/10\n150000/150000 [==============================] - 13s 89us/sample - loss: 0.5179 - binary_accuracy: 0.7219s - loss: 0.5201 - binary_accuracy: 0 - ETA: 8s - loss: 0.5211 - binary_a - ETA: 9s - loss: 0.5208 - binary_accuracy: 0.721 - ETA: 8s - loss: 0.5201 - binary_accuracy: 0.72 - ETA: 8s - loss: 0.5210 - - ETA: 7s - loss: 0.5180 - binary_ac - ETA: 7s - loss: 0.5187 - binar - ETA: 6s - loss: 0.5186 - binary_accura - ETA: 6s - loss: 0.5183 - binary_accuracy: 0.7 - ETA: 6s - loss: 0.5182 - binary_ac - ETA: 5s - loss: 0.5179 - binary_accuracy: 0.723 - ETA: 5s - loss: 0.5179 - binary_accurac - ETA: 4s - loss: 0.5187 - binary_accuracy: 0.722 - ETA: 4s - lo\nEpoch 5/10\n150000/150000 [==============================] - 13s 87us/sample - loss: 0.5132 - binary_accuracy: 0.72531s - loss: 0.5093 - binary_accuracy: 0.72 - ETA: 11s - ETA: 9s - loss: 0.5156 - binary_accuracy: 0.7 - ETA: 9s - loss: 0.5163 - binary_accuracy:  - ETA: 9s - loss: 0.5154 - binary_accurac - ETA: 8s - loss: 0.5164 - bin - ETA: 7s - loss: 0.5156 - binary - ETA: 6s - loss: 0.5168 - binary_accuracy: 0. - ETA: 6s - loss: 0.5163 - binary_accuracy: 0.72 - ETA: 6s - loss: 0.5160 - binary_accur - ETA: 5s - loss: 0.5154 - binary_accuracy: 0.723 - ETA: 5s - loss: 0.5153 - binary_a - ETA: 4s - los - ETA: 2s - loss: 0.5136 - binary_acc - ETA: 1s - loss: 0.5135 - binary_accuracy: 0.724 - ETA: 1s - loss: 0.5134 - binary_accuracy - ETA: 1s - loss: 0.5132 - binary_ac\nEpoch 6/10\n150000/150000 [==============================] - 13s 87us/sample - loss: 0.5094 - binary_accuracy: 0.72850s - loss: 0.4971 - binary_accuracy: 0.73 - ETA: 11s - loss: 0.5000 - binary_ - ETA: 9s - loss: 0.5043 - binary_accuracy: - ETA: 10s - loss: 0.5081 - binary_accuracy:  - ETA: 9s - loss: 0.5086 - binary_a - ETA: 9s - loss: 0.5106 - binary_accuracy: 0 - ETA: 9s - loss: 0.5111 - binary_accuracy: 0.72 - ETA: 9s - loss: 0.5112 - binary_accuracy:  - ETA: 9s - loss: 0.5122 - binary_accuracy: 0.724 - ETA: 9s - loss: 0.5122 - binary_accuracy:  - ETA: 8s - loss: 0.5114 - binary_accuracy: 0. - ETA: 8s - loss: 0.5115 - binary_accuracy: 0. - ETA: 8s - loss: 0.5118 - binary_accuracy: 0 - ETA: 8s - loss: 0.5111 - binary_accuracy: 0.725 - ETA: 8s - loss: 0.5114 - - ETA: 6s - loss: 0.5099 - binary_accuracy - ETA: 6s - loss: 0.5108 - binary_accuracy - ETA: 5s - loss: 0.5100 - binary_accuracy: 0.726 - ETA: 5s - loss: 0.5102 - binary_acc - ETA: 4s - loss: 0.5102 - binary_accurac - ETA: 4s - loss: 0.5102 - binary_accuracy: 0.7 - ETA: 4s - l - ETA: 1s - loss: 0.5102 - binary_accu - ETA: 1s - loss: 0.5098 - bi - ETA: 0s - loss: 0.5094 - binary_accuracy: 0.72\nEpoch 7/10\n150000/150000 [==============================] - 12s 79us/sample - loss: 0.5064 - binary_accuracy: 0.73061s - loss: 0.5050 - binary_accura - ETA: 9s - loss: 0.5096 - binary_accuracy: 0.72 - ETA: 9s - loss: 0.5090 - binary_accuracy - ETA: 8s - loss: 0.5083 - binary_accuracy: 0.7 - ETA: 8s - loss: 0.5082 - binary_accuracy: 0.7 - ETA: 8s - loss: 0.5083 - binary_accur - ETA: 7s - loss: 0.5085 - binary_accuracy: 0 - ETA: 6s - loss: 0.5079 - binary_a - ETA: 5s - loss: 0.5079 - binary_accuracy: 0. - ETA: 5s - loss: 0.5080 - binary_accuracy:  - ETA: 5s - loss: 0.5078 - binary_accuracy - ETA: 4s - loss: 0.5081 - binary_accuracy: 0 - ETA: 4s - loss: 0.5080 - binary_accuracy: 0.730 - ETA: 4s - loss: 0.5080 - binary_accuracy: 0.730 - ETA: 4s - loss: 0.5078 - binary_accuracy:  - ETA: 4s - loss: 0.5072 - binary_accuracy: 0 - ETA: 3s - loss: 0.5072 - binary_ - ETA: 2s - lo - ETA: 0s - loss: 0.5064 - binary_accuracy: 0.730\nEpoch 8/10\n150000/150000 [==============================] - 13s 85us/sample - loss: 0.5037 - binary_accuracy: 0.73210s - loss: 0.5053 - binary_acc - ETA: 9s - loss: 0.5045 - binary_accuracy:  - ETA: 9s - loss: 0.5024 - binary_accu - ETA: 8s - loss: 0.5013 - binary_accu - ETA: 8s - loss: 0.5014 - binary_accuracy: 0.73 - ETA: 8s - loss: 0.5007 - binar - ETA: 6s - loss: 0.5013 - binary_a - ETA: 6s - loss: 0.5016 - binary_accuracy:  - ETA: 6s - loss: 0.5019 - binary_accuracy: 0.73 - ETA: 5s - loss: 0.5019 - binary_accuracy: 0 - ETA: 5s - loss: 0.5023 - binary_accuracy: 0.73 - ETA: 5s - loss: 0.5021 - binary_accuracy: 0.73 - ETA: 5s - l - ETA: 3s - loss: 0.5027 - ETA: 2s - loss: 0.5036 - binary_accuracy:  - ETA: 2s - loss: 0.5033 - binary_accuracy: 0.732 - ETA: 2s - loss: 0.5033 - binary_accuracy: 0.73 - ETA: 2s - loss: 0.5034 - binary_accur - ETA: 1s - loss: 0.5035 - binary_accuracy:  - ETA: 0s - loss: 0.5033 - binary_accuracy:  - ETA: 0s - loss: 0.5035 - binary_acc\nEpoch 9/10\n150000/150000 [==============================] - 13s 85us/sample - loss: 0.5015 - binary_accuracy: 0.7337s - loss: 0.5023 - binary_accu - ETA: 13s - loss: 0.4956 - binary_accuracy: 0. - ETA: 14s - loss: 0.4949 - binary_accu - ETA: 15s - loss: 0.4938 - binary_accuracy: 0. - ETA: 15s - loss: 0.4977 - binary_accuracy: 0.73 - ETA: 15s - loss: 0.4981 - binary_accuracy: 0. - ETA: 14s - loss:  - ETA: 12s - loss: 0.4989 - binary_accuracy - ETA: 12s - loss: 0.4992 - binary_accuracy - ETA: 11s - loss: 0.4990 - binary_ - ETA: 10s - loss: 0.4982 - binary_accuracy: 0.73 - ETA: 10s - loss: 0.4982 - binar - ETA: 9s - loss: 0.4997 - binary_accuracy: 0. - ETA: 9s - loss: 0.4997 - binary_accuracy: 0 - ETA: 8s - loss: 0.4996 - binary_accuracy: 0.7 - ETA: 8s - loss: 0.4997 - binary - ETA: 7s - loss: 0.5011 - bina - ETA: 6s - loss: 0.5014 - binary_accuracy: 0.7 - ETA: 6s - loss: 0.5011 - binary_ - ETA: 4s - loss: 0.5016 - binary_accuracy: 0.733 - ETA: 4s - loss: 0.5017 - binary_accurac - ETA: 4s - loss: 0.5018 - binary_ac - ETA: 2s - loss: 0.5022 - binary_accuracy: 0.7 - ETA: 2s - loss: 0.5023 - binary_accuracy: 0.73 - ETA: 2s - loss: 0.5021 - binary_accuracy: - ETA: 1s - loss: 0.5018 - binary_accuracy: 0 - ETA: 1s - loss: 0.5019 - binary_accuracy - ETA: 1s - loss: 0.5018 - binary_accuracy: 0.73 - ETA: 1s - loss: 0.5018 - binary_accuracy: 0.7 - ETA: 1s - loss: 0.5017 - binary_a\nEpoch 10/10\n150000/150000 [==============================] - 14s 91us/sample - loss: 0.4995 - binary_accuracy: 0.73620s - loss: 0.4948 - binary_accuracy:  - ETA: 14s - loss: 0.4965 - binary_accura - ETA: 14s - loss: 0.4980 - binary_accu - ETA: 12s - loss: 0.4973 - binary_accuracy - ETA: 12s - loss: 0.5014 - binar - ETA: 12s - loss: 0.4992 - binary_accuracy - ETA: 12s - loss: 0.4996 - binary_accuracy:  - ETA: 12s - loss: 0.5001 - binary_accuracy: 0.73 - ETA: 12s - loss: 0.5003 - binary_accura - ETA: 11s - loss: 0.5011 - b - ETA: 9s - loss: 0.5027 - binary_accuracy:  - ETA: 9s - loss: 0.5026 - binary_accuracy - ETA: 8s - loss: 0.5013 - binary_accur - ETA: 8s - loss:  - ETA: 6s - loss: 0.5013 - binary_ - ETA: 5s - loss: 0.5006 - binary_ac - ETA: 4s - loss: 0.4997 - binary_accurac - ETA: 4s - loss: 0.5001 - binary_ac - ETA: 3s - loss: 0.5001 - b - ETA: 1s - loss: 0.4989 - binary_accuracy: 0.736 - ETA: 1s - loss: 0.4989 - binary_accuracy: 0.736 - ETA: 1s - loss: 0.4988 - binary_accuracy: 0.736 - ETA: 1s - loss: 0.4989 - binary_accurac - ETA: 1s - loss: 0.4991 - binary_accuracy: 0. - ETA: 0s - loss: 0.4993 - binary_accura - ETA: 0s - loss: 0.4995 - binary_accuracy: 0.73\n\n&lt;tensorflow.python.keras.callbacks.History at 0x1967af62ac8&gt;</code></pre></div>\n<h3 id=\"모델-평가\" style=\"position:relative;\"><a href=\"#%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80\" aria-label=\"모델 평가 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>모델 평가</h3>\n<p>학습데이터를 이용해 모델 학습이 끝났다면 테스트 데이터를 가지고 모델을 평가해보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">results <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">50000/50000 [==============================] - 12s 234us/sample - loss: 0.5198 - binary_accuracy: 0.7184s - loss: 0.5197 - b - ETA: 11s - loss: 0.5199 - binary_accuracy: 0.  - ETA: 1s - loss: 0.5198 - b</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#loss: 0.5, acc: 0.7</span>\nresults</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[0.5197769028568268, 0.71842]</code></pre></div>\n<blockquote>\n<p>여기서는 100건으로 했기때문에 좀 낮은 71%의 정확도가 나왔다. 아마 사용한 토큰수를 100개가 아닌 10000개로 했다면 85%정도의 정확도를 확인할 수 있을 것이다.</p>\n</blockquote>\n<p>팁으로 힘들게 만든 모델을 아래와 같이 저장해두고 나중에 로드해서 사용할수 있으니 꼭 알아두자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#모델을 저장해둘수도 있다.</span>\nmodel<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token string\">'movie_review_model.h5'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 모델 불러오기</span>\n<span class=\"token comment\">#from keras.models import load_model</span>\n<span class=\"token comment\">#model = load_model('movie_review_model.h5')</span></code></pre></div>\n<h3 id=\"결과-예측하기\" style=\"position:relative;\"><a href=\"#%EA%B2%B0%EA%B3%BC-%EC%98%88%EC%B8%A1%ED%95%98%EA%B8%B0\" aria-label=\"결과 예측하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>결과 예측하기</h3>\n<p>이제 리뷰 문자열을 받아 바로 결과를 예측하는 함수를 만들어 보자</p>\n<p>데이터 형태를 맞추기 위해 np.expand_dims 매서드를 이용해 array의 축을 확장 시켜주어야 한다.</p>\n<p>최종 확률이 0.5 이상이면 긍정, 그렇지 않으면 부정이라고 예측을 하겠다.</p>\n<p>대략 테스트를 먼저 해보고...</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">review <span class=\"token operator\">=</span> <span class=\"token string\">\"아주 재미 있어요\"</span>\ntoken <span class=\"token operator\">=</span> tokenize<span class=\"token punctuation\">(</span>review<span class=\"token punctuation\">)</span>\ntoken</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[&#39;아주/Noun&#39;, &#39;재미/Noun&#39;, &#39;있다/Adjective&#39;]</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">tf <span class=\"token operator\">=</span> term_frequency<span class=\"token punctuation\">(</span>token<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">data <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>expand_dims<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>asarray<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float32'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">0.9102853536605835</code></pre></div>\n<p>테스트한 로직을 함수화해서 사용하자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">predict_review</span><span class=\"token punctuation\">(</span>review<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    token <span class=\"token operator\">=</span> tokenize<span class=\"token punctuation\">(</span>review<span class=\"token punctuation\">)</span>\n    tfq <span class=\"token operator\">=</span> term_frequency<span class=\"token punctuation\">(</span>token<span class=\"token punctuation\">)</span>\n    data <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>expand_dims<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>asarray<span class=\"token punctuation\">(</span>tfq<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float32'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n    score <span class=\"token operator\">=</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>score <span class=\"token operator\">></span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>review<span class=\"token punctuation\">}</span></span><span class=\"token string\"> ==> 긍정 (</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>score<span class=\"token operator\">*</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">%)\"</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>review<span class=\"token punctuation\">}</span></span><span class=\"token string\"> ==> 부정 (</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token operator\">-</span>score<span class=\"token punctuation\">)</span><span class=\"token operator\">*</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">%)\"</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">predict_review<span class=\"token punctuation\">(</span><span class=\"token string\">\"재미 정말 없어요\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">재미 정말 없어요 ==&gt; 부정 (93%)</code></pre></div>\n<p>이제 리뷰텍스트 만으로 긍정인지 혹은 부정인지를 어느정도 판단 할 수 있게 되었다.</p>\n<p>지금까지 영화리뷰 데이터를 통해서 감정분석을 해보았는데 상품, 게임, 음식등의 사용자 의견이 담긴 데이터를 잘 모아서 활용한다면 다양한 곳에 활용할 수 있을 것이다.</p>"},"primaryTag":{"name":"ML-DL","color":"#4bc822"}},"pageContext":{"postId":"b5e7e0a8-312a-51e5-9ebd-3593f9e40b99","primaryTag":"ML-DL"}}}